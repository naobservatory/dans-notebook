{
  "hash": "0ad22e28cb51dad54ebbc9418e207272",
  "result": {
    "markdown": "---\ntitle: Detection sensitivity to read count noise\nauthor: Dan Rice\ndate: '2024-01-19'\nformat:\n  html:\n    code-fold: false\n    toc: true\nfilters:\n  - black-formatter\n---\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.lines as mlines\nfrom scipy.special import digamma\n```\n:::\n\n\n## Background\n\nSee [all-hands memo](https://docs.google.com/document/d/106n3cdhe6rYnIVl3hWHaWcy2Kh2W2i-AOSvr1btBupg/edit#heading=h.31ehajnqsoh5).\n\n## Theory\n\n### Read count model\n\nPoisson counting noise mixed with a latent distribution.\nFor viral read counts $C$ and total per-sample read count $n$:\n\n$C \\sim Poisson(n X)$,\n\nwhere $X$ follows a latent distribution (specified below).\nThis latent distribution should increase in expectation with the prevalence and also capture non-Poisson noise.\n\nWe can show that the coefficient of variation obeys:\n\n$CV[C]^2 = \\frac{1}{n E[X]} + CV[X]$.\n\nThat is, once we expect to see more than one read, the CV of the latent distribution will start to dominate the variation in counts.\n\n### Properties of latent distributions\n\nWe need to specify and parameterize the latent distribution.\nEach distribution will have its own usual parameters, but we want to put them on common footing.\nThis means specifying:\n\n1. A central value (mean, median, etc)\n2. A measure of spread (stdev, etc).\n\nFor spread, we will use the coefficient of variation.\nCaveat: it's not clear that this should be constant as the the mean grows.\nNeed to think about this mechanistically.\n\nFor central value, we'll try specifying two different ways:\n\n1. Arithmetic mean = prevalence X P2RA factor\n1. Geometric mean = prevalence X P2RA factor\n\nThe former is more natural for the gamma distribution, the latter for the lognormal, but we'll try each both ways for comparison.\n\n#### Gamma distribution\n\n- MaxEnt distribution fixing $E[X]$ and $E[\\log X]$\n- Usually specified by shape parameter $k$ and scale parameter $\\theta$\n- $AM = E[X] = k\\theta$\n- $GM = \\exp E[\\log X] = e^{\\psi(k)} \\theta$, where $\\psi$ is the digamma function.\n- $Var[X] = k \\theta^2$\n- $CV[X]^2 = 1/k$\n- $AM / GM = k e^{-\\psi(k)} \\sim k e^{1/k}, k \\to 0$. This is exponentially big in $CV^2$.\n- On linear scale, density has an interior mode when $k > 1$, a mode at zero when $k = 1$ and a power-law sigularity at zero when $k < 1$.\n- On a log scale, the density of $Y = \\log X$ is: $f(y) \\propto \\exp[ky - e^y / \\theta]$. Has a peak at $\\hat{y} = \\log \\theta k$, slow decay to the left, fast decay to the right.\n\n#### Log-normal distribution\n\n- MaxEnt distrib fixing geometric mean and variance\n- Specified by mean and variance of $\\log X$\n- $AM = e^{\\mu + \\sigma^2 / 2}$\n- $GM = e^{\\mu}$\n- $Var[X] = [\\exp(\\sigma^2) - 1] \\exp(2 \\mu + \\sigma^2)$\n- $CV[X]^2 = e^{\\sigma^2} - 1$\n- $AM / GM = e^{\\sigma^2 / 2}$, linear in CV for large CV.\n\n\nBoth distributions have $AM > GM$. But it grows much faster with CV for Gamma.\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\n# Test\nx = 1*2\n```\n:::\n\n\n## Parameters\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\nsampling_period = 7\ndaily_depth = 1e8\nsampling_depth = sampling_period * daily_depth\n\ndoubling_time = 7\ngrowth_rate = np.log(2) / doubling_time\n\n# Boston metro area\npopulation_size = 5e6\n\n# P2RA factor (roughly covid in Rothman)\n# normalize by the fact that we estimate per 1% incidence/prevalence there\np2ra = 1e-7 / 1e-2\n```\n:::\n\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\nmax_prevalence = 0.2\nmax_time = np.ceil(np.log(population_size * max_prevalence) / growth_rate)\n\ntime = np.arange(0, int(max_time) + sampling_period, sampling_period)\nprevalence = np.exp(growth_rate * time) / population_size\n\nrng = np.random.default_rng(seed=10343)\n```\n:::\n\n\n## Simulation\n\n### Threshold detection\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\ndef get_detection_times(time, counts, threshold: float):\n    indices = np.argmax(np.cumsum(counts, axis=1) >= threshold, axis=1)\n    # FIXME: if never detected, indices will be 0, replace with -1 so that we get the largest time\n    # indices[indices == 0] = -1\n    return time[indices]\n```\n:::\n\n\n### Parameterization\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\ndef params_lognormal(mean, cv, mean_type):\n    sigma_2 = np.log(1 + cv**2)\n    if mean_type == \"geom\":\n        mu = np.log(mean)\n    elif mean_type == \"arith\":\n        mu = np.log(mean) - sigma_2 / 2\n    else:\n        raise ValueError(\"mean_type must be geom|arith\")\n    return mu, np.sqrt(sigma_2)\n\n\ndef params_gamma(mean, cv, mean_type):\n    shape = cv ** (-2)\n    if mean_type == \"geom\":\n        scale = mean * np.exp(-digamma(shape))\n    elif mean_type == \"arith\":\n        scale = mean / shape\n    else:\n        raise ValueError(\"mean_type must be geom|arith\")\n    return shape, scale\n```\n:::\n\n\n### Count simulation\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\ndef simulate_latent(\n    mean,\n    cv: float, # coefficient of variation\n    mean_type: str, # geom | arith\n    distribution: str, # gamma | lognormal\n    num_reps: int = 1,\n    rng: np.random.Generator = np.random.default_rng(), # CHECK\n):\n    size = (num_reps, len(mean))\n    if distribution == \"gamma\":\n        shape, scale = params_gamma(mean, cv, mean_type)\n        return rng.gamma(shape, scale, size)\n    elif distribution == \"lognormal\":\n        mu, sigma = params_lognormal(mean, cv, mean_type)\n        return rng.lognormal(mu, sigma, size)\n    else:\n        raise ValueError(\"distribution must be gamma|lognormal\")\n\n\ndef simulate_counts(\n    prevalence,\n    p2ra: float,\n    sampling_depth: float,\n    cv: float, # coefficient of variation\n    mean_type: str, # geom | arith\n    latent_dist: str, # gamma | lognormal\n    num_reps: int = 1,\n    rng: np.random.Generator = np.random.default_rng(), # CHECK\n):\n    relative_abundance = p2ra * prevalence\n    lamb = simulate_latent(relative_abundance, cv, mean_type, latent_dist, num_reps, rng)\n    counts = rng.poisson(sampling_depth * lamb)\n    return counts\n```\n:::\n\n\n### Test latent params\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\nt = np.arange(100)\nmean = 0.01 * np.exp(t / 7)\ncvs = [0.5, 1.0, 2, 4]\nnum_reps = 1000\n\nfor cv in cvs:\n    latent = simulate_latent(mean, cv, \"arith\", \"gamma\", num_reps, rng)\n    plt.semilogy(t, np.mean(latent, axis=0))\n    plt.semilogy(t, np.std(latent, axis=0))\n    plt.semilogy(t, mean, \"--k\")\n    plt.semilogy(t, mean * cv, \":k\")\n    plt.title(f\"CV = {cv}\")\n    plt.show()\n\nfor cv in cvs:\n    latent = simulate_latent(mean, cv, \"arith\", \"lognormal\", num_reps, rng)\n    plt.semilogy(t, np.mean(latent, axis=0))\n    plt.semilogy(t, np.std(latent, axis=0))\n    plt.semilogy(t, mean, \"--k\")\n    plt.semilogy(t, mean * cv, \":k\")\n    plt.title(f\"CV = {cv}\")\n    plt.show()\n\nfor cv in cvs:\n    latent = simulate_latent(mean, cv, \"geom\", \"gamma\", num_reps, rng)\n    plt.semilogy(t, np.exp(np.mean(np.log(latent), axis=0)))\n    plt.semilogy(t, np.std(latent, axis=0))\n    plt.semilogy(t, np.mean(latent, axis=0))\n    print(np.std(latent, axis=0) / np.mean(latent, axis=0))\n    plt.semilogy(t, mean, \"--k\")\n    plt.title(f\"CV = {cv}\")\n    plt.show()\n\nfor cv in cvs:\n    latent = simulate_latent(mean, cv, \"geom\", \"lognormal\", num_reps, rng)\n    plt.semilogy(t, np.exp(np.mean(np.log(latent), axis=0)))\n    plt.semilogy(t, np.std(latent, axis=0))\n    plt.semilogy(t, np.mean(latent, axis=0))\n    plt.semilogy(t, mean, \"--k\")\n    plt.title(f\"CV = {cv}\")\n    plt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](2024-01-19_SimpleSensitivity_files/figure-html/cell-9-output-1.png){width=580 height=431}\n:::\n\n::: {.cell-output .cell-output-display}\n![](2024-01-19_SimpleSensitivity_files/figure-html/cell-9-output-2.png){width=580 height=431}\n:::\n\n::: {.cell-output .cell-output-display}\n![](2024-01-19_SimpleSensitivity_files/figure-html/cell-9-output-3.png){width=580 height=431}\n:::\n\n::: {.cell-output .cell-output-display}\n![](2024-01-19_SimpleSensitivity_files/figure-html/cell-9-output-4.png){width=580 height=431}\n:::\n\n::: {.cell-output .cell-output-display}\n![](2024-01-19_SimpleSensitivity_files/figure-html/cell-9-output-5.png){width=580 height=431}\n:::\n\n::: {.cell-output .cell-output-display}\n![](2024-01-19_SimpleSensitivity_files/figure-html/cell-9-output-6.png){width=580 height=431}\n:::\n\n::: {.cell-output .cell-output-display}\n![](2024-01-19_SimpleSensitivity_files/figure-html/cell-9-output-7.png){width=580 height=431}\n:::\n\n::: {.cell-output .cell-output-display}\n![](2024-01-19_SimpleSensitivity_files/figure-html/cell-9-output-8.png){width=580 height=431}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n[0.50348026 0.49182015 0.50282823 0.50870395 0.49265948 0.50533411\n 0.52211055 0.50050186 0.49085442 0.48295105 0.51659485 0.47924307\n 0.51916236 0.49989031 0.47911488 0.50655809 0.5040264  0.50973589\n 0.5259777  0.521355   0.51196868 0.50614298 0.5106999  0.52373657\n 0.47330863 0.50842704 0.51643281 0.47957447 0.50206644 0.50377273\n 0.49816772 0.51913592 0.52782476 0.49194066 0.51983427 0.52527224\n 0.49243682 0.49117164 0.5037379  0.48340348 0.4940295  0.49636163\n 0.52741949 0.49278562 0.50890312 0.51281443 0.47388754 0.51449679\n 0.49937058 0.48876435 0.50115377 0.52301337 0.50080361 0.50482404\n 0.50357979 0.50982194 0.48190781 0.49510878 0.48948755 0.48957791\n 0.49904929 0.49695378 0.4944266  0.49329813 0.51841087 0.49790695\n 0.49476528 0.48351475 0.51986067 0.48381848 0.49908738 0.49081166\n 0.50835463 0.49487533 0.49129641 0.51527339 0.50583592 0.49600538\n 0.49727427 0.50392921 0.49140025 0.50015994 0.49576992 0.50345842\n 0.49471129 0.51298593 0.47710101 0.47296923 0.4792705  0.51883331\n 0.49841553 0.51106549 0.51211019 0.48844829 0.50808292 0.51041238\n 0.49871134 0.49191981 0.47683314 0.51868499]\n[0.98393079 1.02228662 1.02012703 0.98510473 0.99054394 1.05067537\n 0.98531434 1.01228511 0.98334931 1.01326723 0.97723524 0.98954736\n 1.03536915 1.01491756 1.01645102 0.97640239 0.97622787 0.98144578\n 0.97274661 1.01520805 0.95254337 1.00135342 0.97954303 1.00187655\n 1.06584758 1.00567692 1.00412554 0.97124493 0.9312591  0.99823349\n 0.963092   1.00199325 1.03445693 1.06515596 1.06077553 0.97742492\n 1.08236563 0.90886172 0.99237003 1.01603279 1.03544314 0.94547342\n 0.99914824 1.02062342 0.99032014 0.97735808 1.00704571 0.99753384\n 1.04174574 0.99912939 0.97997322 0.98636165 0.98046552 0.96440814\n 0.98053455 1.00069747 1.02727122 0.95428542 0.97861231 0.96537031\n 0.99165826 0.98666603 0.98276165 0.95895163 0.97315295 0.96513772\n 1.01242235 1.02112884 1.0552492  0.97147578 0.98236027 1.01597814\n 1.00647088 1.00451165 1.01165352 1.02227556 0.98477906 1.08072714\n 0.99728964 1.01029694 1.00368864 0.98316007 0.97854387 0.97504436\n 0.97201678 1.05501862 1.03827394 1.00967839 1.02932978 1.00375372\n 1.02989618 0.94712783 0.97704349 1.03746789 1.00793446 0.99466767\n 0.97315889 1.03402584 0.99440691 0.99421547]\n[1.93348289 1.94075628 1.9371521  2.0596737  2.01922064 1.77050199\n 1.95359177 2.21491995 1.76238332 2.01896386 1.8359474  1.93522955\n 1.92304791 2.07436114 2.00112383 1.92611896 1.91318319 1.89199837\n 1.95239552 1.94197283 1.96052082 2.04660114 2.11607495 1.91440194\n 1.87350164 1.87829558 1.96142867 2.18442557 1.88364222 1.87840667\n 2.10924738 1.94424085 2.01537714 1.99424229 1.84297648 1.8983749\n 2.05230387 2.0670051  1.96440085 1.98658515 1.94209637 1.8520699\n 2.08009187 2.06838783 1.79127993 1.87616927 1.97531894 1.985033\n 2.11656599 1.89554444 1.95982964 2.12635557 2.03685668 1.90855538\n 2.019133   1.93651675 1.8725479  1.99982613 1.99215463 2.10543879\n 1.95080877 1.90585074 1.9536033  2.02331806 1.90023477 2.03508627\n 1.93722256 1.89147195 1.95247127 1.91292066 1.96191177 2.04529256\n 1.90620202 2.05602709 2.04635604 1.9964848  2.06337469 1.91445034\n 1.98958428 1.90751535 1.87740487 2.12006546 1.80767642 1.91483707\n 1.89387481 2.03026639 1.98127219 1.96318601 2.01879857 1.9100694\n 1.98198117 2.11591477 2.03354811 2.20515637 1.86657211 1.9549832\n 2.03214746 2.01828408 2.01163885 2.19198731]\n[3.85885115 4.15112238 3.92872672 3.60005621 4.11774644 4.04874281\n 3.76652958 3.56179868 3.75387821 4.72929878 4.51766138 4.09093613\n 3.4065016  4.29871855 3.66379723 4.05704088 3.50161145 4.0989186\n 3.93898714 3.76942373 3.82458744 4.49414312 4.08017117 3.79421135\n 4.19901864 3.55467022 3.71045934 3.91660997 4.27304547 4.20155975\n 3.78045465 4.09401223 4.13905594 3.78531078 3.90054913 4.04997723\n 3.7416698  3.61782184 4.01523185 3.61314766 4.57979094 3.80476479\n 4.2427299  4.53425588 3.90922339 4.62143615 3.48617567 3.87590464\n 3.84146648 3.7905067  3.57560193 3.93392831 3.31075887 4.12729374\n 4.29561327 4.20645896 3.6806276  4.23596369 4.04506462 4.67984352\n 4.23507313 4.34065718 4.28223705 3.67078099 4.04157157 4.68677653\n 4.2690662  3.57520629 4.05247374 4.02668955 4.41856066 3.62780225\n 3.64177031 4.27659845 3.80032842 3.78244861 3.56100671 4.10671816\n 3.55325258 4.55545487 4.29575367 4.3634054  3.74042498 3.99472887\n 3.3625012  3.86508634 3.74088776 4.77547092 3.77768133 3.95763258\n 3.27596278 4.1696738  4.1919582  3.87427013 3.6489727  4.12122796\n 3.91741195 3.4060893  3.70814923 4.08789586]\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](2024-01-19_SimpleSensitivity_files/figure-html/cell-9-output-10.png){width=580 height=431}\n:::\n\n::: {.cell-output .cell-output-display}\n![](2024-01-19_SimpleSensitivity_files/figure-html/cell-9-output-11.png){width=580 height=431}\n:::\n\n::: {.cell-output .cell-output-display}\n![](2024-01-19_SimpleSensitivity_files/figure-html/cell-9-output-12.png){width=580 height=431}\n:::\n\n::: {.cell-output .cell-output-display}\n![](2024-01-19_SimpleSensitivity_files/figure-html/cell-9-output-13.png){width=580 height=431}\n:::\n\n::: {.cell-output .cell-output-display}\n![](2024-01-19_SimpleSensitivity_files/figure-html/cell-9-output-14.png){width=580 height=431}\n:::\n\n::: {.cell-output .cell-output-display}\n![](2024-01-19_SimpleSensitivity_files/figure-html/cell-9-output-15.png){width=580 height=431}\n:::\n\n::: {.cell-output .cell-output-display}\n![](2024-01-19_SimpleSensitivity_files/figure-html/cell-9-output-16.png){width=580 height=431}\n:::\n\n::: {.cell-output .cell-output-display}\n![](2024-01-19_SimpleSensitivity_files/figure-html/cell-9-output-17.png){width=580 height=431}\n:::\n:::\n\n\n## Results\n\n### Counts\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\nnum_reps = 1000\ncvs = [0.25, 0.5, 1.0, 2, 4]\n\ncounts_ga = [simulate_counts(prevalence, p2ra, sampling_depth, cv, mean_type=\"arith\", latent_dist=\"gamma\", num_reps=num_reps, rng=rng) for cv in cvs]\ncounts_la = [simulate_counts(prevalence, p2ra, sampling_depth, cv, mean_type=\"arith\", latent_dist=\"lognormal\", num_reps=num_reps, rng=rng) for cv in cvs]\ncounts_gg = [simulate_counts(prevalence, p2ra, sampling_depth, cv, mean_type=\"geom\", latent_dist=\"gamma\", num_reps=num_reps, rng=rng) for cv in cvs]\ncounts_lg = [simulate_counts(prevalence, p2ra, sampling_depth, cv, mean_type=\"geom\", latent_dist=\"lognormal\", num_reps=num_reps, rng=rng) for cv in cvs]\n```\n:::\n\n\n#### Arithmetic mean\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\nto_plot = 100\nplt.figure(figsize=(8,4))\nfor i, cv in enumerate(cvs):\n    ax = plt.subplot(2, len(cvs), i + 1)\n    ax.semilogy(time, counts_ga[i][:to_plot].T, '.', color = \"C0\", alpha = 0.1)\n    ax.semilogy(time, sampling_depth * p2ra * prevalence, \"k--\")\n    ax.set_title(r\"$CV = $\" + f\"{cv}\")\n    ax.set_ylim([1, 1e5])\n    if i == 0:\n        ax.set_ylabel(\"Count\")\n    else:\n        ax.set_yticklabels([])\n    ax = plt.subplot(2, len(cvs), len(cvs) + i + 1)\n    ax.semilogy(time, counts_la[i][:to_plot].T, '.', color = \"C0\", alpha = 0.1)\n    ax.semilogy(time, sampling_depth * p2ra * prevalence, \"k--\")\n    ax.set_ylim([1, 1e5])\n    if i == 0:\n        ax.set_ylabel(\"Count\")\n    else:\n        ax.set_yticklabels([])\n    ax.set_xlabel(\"Day\")\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](2024-01-19_SimpleSensitivity_files/figure-html/cell-11-output-1.png){width=666 height=376}\n:::\n:::\n\n\n#### Geometric mean\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\nplt.figure(figsize=(8,4))\nfor i, cv in enumerate(cvs):\n    ax = plt.subplot(2, len(cvs), i + 1)\n    ax.semilogy(time, counts_gg[i][:to_plot].T, '.', color = \"C0\", alpha = 0.1)\n    ax.semilogy(time, sampling_depth * p2ra * prevalence, \"k--\")\n    ax.set_title(r\"$CV = $\" + f\"{cv}\")\n    ax.set_ylim([1, 1e5])\n    if i == 0:\n        ax.set_ylabel(\"Count\")\n    else:\n        ax.set_yticklabels([])\n    ax = plt.subplot(2, len(cvs), len(cvs) + i + 1)\n    ax.semilogy(time, counts_lg[i][:to_plot].T, '.', color = \"C0\", alpha = 0.1)\n    ax.semilogy(time, sampling_depth * p2ra * prevalence, \"k--\")\n    ax.set_ylim([1, 1e5])\n    if i == 0:\n        ax.set_ylabel(\"Count\")\n    else:\n        ax.set_yticklabels([])\n    ax.set_xlabel(\"Day\")\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](2024-01-19_SimpleSensitivity_files/figure-html/cell-12-output-1.png){width=666 height=376}\n:::\n:::\n\n\n### Cumulative counts\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\nplt.figure(figsize=(8,8))\nfor i, cv in enumerate(cvs):\n    ax = plt.subplot(4, len(cvs), i + 1)\n    ax.semilogy(time, np.cumsum(counts_ga[i][:to_plot], axis=1).T, '-', color = \"C0\", alpha = 0.1)\n    ax.semilogy(time, np.cumsum(sampling_depth * p2ra * prevalence), \"k--\")\n    ax.set_title(r\"$CV = $\" + f\"{cv}\")\n    ax.set_ylim([1, 1e5])\n    if i == 0:\n        ax.set_ylabel(\"Cumulative count\")\n        ax.text(0, 1e4, \"Arithmetic\\nGamma\")\n    else:\n        ax.set_yticklabels([])\n    ax = plt.subplot(4, len(cvs), len(cvs) + i + 1)\n    ax.semilogy(time, np.cumsum(counts_la[i][:to_plot], axis=1).T, '-', color = \"C1\", alpha = 0.1)\n    ax.semilogy(time, np.cumsum(sampling_depth * p2ra * prevalence), \"k--\")\n    ax.set_ylim([1, 1e5])\n    if i == 0:\n        ax.set_ylabel(\"Cumulative count\")\n        ax.text(0, 1e4, \"Arithmetic\\nLognormal\")\n    else:\n        ax.set_yticklabels([])\n\n    ax = plt.subplot(4, len(cvs), 2 * len(cvs) + i + 1)\n    ax.semilogy(time, np.cumsum(counts_gg[i][:to_plot], axis=1).T, '-', color = \"C0\", alpha = 0.1)\n    ax.semilogy(time, np.cumsum(sampling_depth * p2ra * prevalence), \"k--\")\n    ax.set_ylim([1, 1e5])\n    if i == 0:\n        ax.set_ylabel(\"Cumulative count\")\n        ax.text(0, 1e4, \"Geometric\\nGamma\")\n    else:\n        ax.set_yticklabels([])\n    ax = plt.subplot(4, len(cvs), 3 * len(cvs) + i + 1)\n    ax.semilogy(time, np.cumsum(counts_lg[i][:to_plot], axis=1).T, '-', color = \"C1\", alpha = 0.1)\n    ax.semilogy(time, np.cumsum(sampling_depth * p2ra * prevalence), \"k--\")\n    ax.set_ylim([1, 1e5])\n    if i == 0:\n        ax.set_ylabel(\"Cumulative count\")\n        ax.text(0, 1e4, \"Geometric\\nLognormal\")\n    else:\n        ax.set_yticklabels([])\n    ax.set_xlabel(\"Day\")\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](2024-01-19_SimpleSensitivity_files/figure-html/cell-13-output-1.png){width=666 height=671}\n:::\n:::\n\n\n### Detection times\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\nthresholds = [2, 100]\ndetection_times_ga = [[get_detection_times(time, counts, threshold) for counts in counts_ga] for threshold in thresholds]\ndetection_times_la = [[get_detection_times(time, counts, threshold) for counts in counts_la] for threshold in thresholds]\ndetection_times_gg = [[get_detection_times(time, counts, threshold) for counts in counts_gg] for threshold in thresholds]\ndetection_times_lg = [[get_detection_times(time, counts, threshold) for counts in counts_lg] for threshold in thresholds]\n```\n:::\n\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\nq = 0.9\n\nax = plt.subplot(111)\n\nplt.semilogx(cvs, [np.quantile(dt, q) for dt in detection_times_ga[0]], 'o-', color=\"C0\")\nplt.semilogx(cvs, [np.quantile(dt, q) for dt in detection_times_la[0]], 'o-', color=\"C1\")\nplt.semilogx(cvs, [np.quantile(dt, q) for dt in detection_times_gg[0]], 'o:', color=\"C0\")\nplt.semilogx(cvs, [np.quantile(dt, q) for dt in detection_times_lg[0]], 'o:', color=\"C1\")\n\nplt.semilogx(cvs, [np.quantile(dt, q) for dt in detection_times_ga[1]], 's-', color=\"C0\", label=\"Gamma-Arith\")\nplt.semilogx(cvs, [np.quantile(dt, q) for dt in detection_times_la[1]], 's-', color=\"C1\", label=\"LN-Arith\")\nplt.semilogx(cvs, [np.quantile(dt, q) for dt in detection_times_gg[1]], 's:', color=\"C0\", label=\"Gamma-Geom\")\nplt.semilogx(cvs, [np.quantile(dt, q) for dt in detection_times_lg[1]], 's:', color=\"C1\", label=\"LN-Geom\")\n\nax.set_ylabel(\"Detection day (90th percentile)\")\nax.set_xscale('log', base=2)\nax.set_xlabel(\"Coefficient of variation\")\nplt.legend(\n    handles = [\n        mlines.Line2D([], [], color=\"C0\", marker=\"o\", label=\"Gamma\"),\n        mlines.Line2D([], [], color=\"C1\", marker=\"o\", label=\"Lognormal\"),\n        mlines.Line2D([], [], color=\"0.5\", linestyle=\"-\", label=\"Arithmetic mean\"),\n        mlines.Line2D([], [], color=\"0.5\", linestyle=\":\", label=\"Geometric mean\"),\n        mlines.Line2D([], [], color=\"0.5\", marker=\"s\", label=\"Threshold = 100\"),\n        mlines.Line2D([], [], color=\"0.5\", marker=\"o\", label=\"Threshold = 2\"),\n    ]\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=27}\n```\n<matplotlib.legend.Legend at 0x16ccc1690>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](2024-01-19_SimpleSensitivity_files/figure-html/cell-15-output-2.png){width=593 height=431}\n:::\n:::\n\n\n",
    "supporting": [
      "2024-01-19_SimpleSensitivity_files"
    ],
    "filters": [],
    "includes": {}
  }
}