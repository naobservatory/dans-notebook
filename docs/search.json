[
  {
    "objectID": "decision-theory/numerical_fredholm_integral.html",
    "href": "decision-theory/numerical_fredholm_integral.html",
    "title": "Introduction",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom numpy.polynomial.laguerre import laggauss\nfrom numpy import linalg\nfrom scipy.stats import norm\nWe want to solve a Fredholm integral equation of the second kind, of the form:\n\\(u(x) = \\int_{0}^{\\infty} K(x, t) u(t) dt + f(x)\\)\nWe’ll approach it by using Gauss-Laguerre quadrature to approximate the integral (note that we have to insert \\(\\exp(t)\\) to cancel the implicit \\(\\exp(-t)\\) weighting function of the G-L quadrature.):\n\\(u(x) \\approx \\sum_{j=1}^{n} w_j \\exp(t_j) K(x, t_j) u(t_j) + f(x)\\)\nIf we evaluate \\(u\\) at the quadrature points (\\(u_i = u(x_i)\\)), we get a linear system:\n\\(u_i \\approx \\sum_{j=1}^{n} w_j \\exp(x_j) K(x_i, x_j) u_j + f(x_i)\\)\nIn matrix form, we have:\n\\(A \\vec{u} = \\vec{b}\\)\n\\(A_{i,j} = \\delta_{i,j} - w_j exp(x_j) K(x_i, x_j)\\)\n\\(b_i = f(x_i)\\)\nWe can solve this for \\(\\vec{u}\\). Then to get the continuous function \\(u(x)\\), we can substitute \\(\\vec{u}\\) into the right-hand side of the approximation above:\n\\(u(x) \\approx \\sum_{j=1}^{n} w_j \\exp(t_j) K(x, t_j) u_j + f(x)\\)\ndef solve_fredholm(k, f, n):\n    x, w = laggauss(n)\n    A = np.eye(n) - w * np.exp(x) * k(x[:,None], x)\n    b = f(x)\n    u = linalg.solve(A, b)\n    def soln(y):\n        return np.dot(w * np.exp(x) * k(y[:,None], x), u) + f(y)\n    return soln\ndef k(mu, sigma):\n    return lambda x, t: norm(loc=mu, scale=sigma).pdf(t - x)\n\ndef f_nt(mu, sigma):\n    return norm(loc=-mu, scale=sigma).sf\n\ndef f_t():\n    return np.ones_like\nAs we increase the number of nodes, we approach the asymptotic behavior (in \\(x\\)) that we expect from theory.\nmu = 1\nsigma = 1\n\nxmax = 5\nx = np.arange(0, xmax, 0.01)\n\nfor n in [5, 10, 20]:\n    plt.plot(x, solve_fredholm(k(-mu, sigma), f_t(), n)(x), label = f\"n = {n}\")\nplt.plot(x, x / mu + 1, 'k--', label=\"asymptotic theory\")\nplt.legend(frameon=False)\nplt.xlabel(r\"$x$\")\nplt.ylabel(r\"$u_T(x)$\")\nplt.show()\n\nfor n in [5, 10, 20]:\n    plt.semilogy(x, solve_fredholm(k(mu, sigma), f_nt(mu, sigma), n)(x), label = f\"n = {n}\")\nplt.plot(x, norm.cdf(-mu/sigma) * np.exp(-2 * mu * x / sigma**2), 'k--', label=\"asymptotic theory\")\nplt.legend(frameon=False)\nplt.xlabel(r\"$x$\")\nplt.ylabel(r\"$u_{NT}(x)$\")\nplt.show()"
  },
  {
    "objectID": "decision-theory/numerical_fredholm_integral.html#scaling-diagrams",
    "href": "decision-theory/numerical_fredholm_integral.html#scaling-diagrams",
    "title": "Introduction",
    "section": "Scaling diagrams",
    "text": "Scaling diagrams\n\nn = 185\nsigma = 1\n\n\nThreat, \\(|\\mu / \\sigma| \\ge 1\\)\n\nxmax = 32\nx = np.arange(0, xmax, 0.01)\n\nfor mu in [-1, -2, -4, -8]:\n    soln = solve_fredholm(k(mu, sigma), f_t(), n)\n    plt.plot(x / (-mu), soln(x), label=mu)\nplt.plot(x, x + 0.5, 'k')\nplt.xlim([0, 4])\nplt.ylim([0, 5])\nplt.xlabel(r\"$x / (-\\mu)$\")\nplt.ylabel(r\"$u(x)$\")\nplt.legend()\n\n&lt;matplotlib.legend.Legend at 0x126fa1f90&gt;\n\n\n\n\n\n\nxmax = 16\nx = np.arange(0, xmax, 0.01)\n\nplt.figure(figsize=(3,2))\nfor mu in [-4, -8]:\n    soln = solve_fredholm(k(mu, sigma), f_t(), n)\n    plt.plot(x, soln(x), label=r\"$\\tau = $\" + f\"{-2 * mu}\")\nplt.xlim([0, xmax])\nplt.ylim([0, 5])\nplt.xlabel(r\"$x$\")\nplt.ylabel(r\"$u_T(x)$\")\nplt.legend(frameon=False)\nplt.savefig(\"large_updates.png\", bbox_inches=\"tight\")\n\n\n\n\n\n\nNon-threat, \\(|\\mu / \\sigma| \\ge 1\\)\nOne term from the Liouville-Neumann series:\n\nfor mu in [1, 2, 3, 4]:\n    xmax = 2*mu\n    x = np.arange(0, xmax, 0.01)\n\n    soln = solve_fredholm(k(mu, sigma), f_nt(mu, sigma), n)\n    plt.semilogy(x / mu, soln(x), label=mu)\n    plt.semilogy(x / mu, norm.cdf(-(x+mu)/sigma))\n    plt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\nMultiple terms from the Liouville-Neumann series:\n\nfor mu in [1, 2, 3, 4]:\n    xmax = 2*mu\n    x = np.arange(0, xmax, 0.01)\n\n    soln = solve_fredholm(k(mu, sigma), f_nt(mu, sigma), n)\n    approx = np.zeros_like(x)\n    for j in range(1, 4):\n        approx += norm.cdf(-(x + j * mu)/(np.sqrt(j) * sigma))\n    plt.semilogy(x / mu, soln(x), label=mu)\n    plt.semilogy(x / mu, approx)\n    plt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNon-threat, \\(|\\mu / \\sigma| \\leq 1\\)\n\nxmax = 32\nx = np.arange(0, xmax, 0.01)\n\nfor mu in [1/8, 1/4, 1/2, 1]:\n    soln = solve_fredholm(k(mu, sigma), f_nt(mu, sigma), n)\n    plt.semilogy(2 * mu * x / sigma**2, soln(x), label=mu)\nplt.semilogy(x, np.exp(- x), 'k')\nplt.xlim([0, 8])\nplt.ylim([1e-4,1])\nplt.xlabel(r\"$2 \\mu x / \\sigma^2$\")\nplt.ylabel(r\"$u(x)$\")\nplt.legend()\n\n&lt;matplotlib.legend.Legend at 0x126fbac10&gt;\n\n\n\n\n\nTesting the hypothesis that \\(u_{NT}(0) \\sim \\frac{1}{1 + \\sqrt{\\tau/2}}\\) for \\(\\tau \\to 0\\).\n\nplt.subplot(211)\nfor mu in np.logspace(-1.5, 0, 20):\n    soln = solve_fredholm(k(mu, sigma), f_nt(mu, sigma), n)\n    plt.loglog(mu, 1 - soln(np.zeros(1)), '.k')\n    plt.loglog(mu, 1 - 1 / (1 + np.sqrt(2)*mu / sigma), 'xk')\nplt.ylabel(r\"$1 - u_{NT}(0)$\")\n\nplt.subplot(212)\nfor mu in np.logspace(-1.5, 0, 20):\n    soln = solve_fredholm(k(mu, sigma), f_nt(mu, sigma), n)\n    plt.semilogx(mu, soln(np.zeros(1)), '.k')\n    plt.semilogx(mu, 1 / (1 + np.sqrt(2)*mu / sigma), 'xk')\n\nplt.xlabel(r\"$\\mu / \\sigma = \\sqrt{\\tau}/2$\")\nplt.ylabel(r\"$u_{NT}(0)$\")\nplt.ylim([0,1])\n\n(0.0, 1.0)\n\n\n\n\n\n\n\nThreat, \\(|\\mu / \\sigma| \\le 1\\)\n\nxmax = 32\nx = np.arange(0, xmax, 0.01)\n\nfor mu in [-1/16, -1/8, -1/4, -1/2, -1]:\n    soln = solve_fredholm(k(mu, sigma), f_t(), n)\n    plt.plot(x / sigma, soln(x) * (-mu / sigma), label=r\"$\\tau = $\" + f\"{-2*mu}\")\nplt.plot(x, x + 0.5, 'k')\nplt.xlim([0, 4])\nplt.ylim([0, 5])\nplt.xlabel(r\"$x / \\sqrt{\\tau}$\")\nplt.ylabel(r\"$\\frac{\\sqrt{\\tau}}{2} u(x)$\")\nplt.legend()\n\n&lt;matplotlib.legend.Legend at 0x130102910&gt;\n\n\n\n\n\n\nxmax = 32\nx = np.arange(0, xmax, 0.01)\n\nfig = plt.figure(figsize=(5.5,2.5))\n\nax = plt.subplot(122)\nfor mu in [-1/8, -1/4, -1/2, -1]:\n    soln = solve_fredholm(k(mu, sigma), f_t(), n)\n    plt.plot(x / sigma, soln(x) * (-mu / sigma), label=f\"{-2*mu}\")\nplt.plot(x, x + 0.5, 'k')\nplt.xlim([0, 4])\nplt.ylim([0, 5])\nplt.xlabel(r\"$x / \\sqrt{\\tau}$\")\nplt.ylabel(r\"$\\frac{\\sqrt{\\tau}}{2} u_{T}(x)$\")\nplt.legend(frameon=False, title=r\"$\\tau$\")\n\n\nxmax = 32\nx = np.arange(0, xmax, 0.01)\n\nax = plt.subplot(121)\nfor mu in [1/8, 1/4, 1/2, 1]:\n    soln = solve_fredholm(k(mu, sigma), f_nt(mu, sigma), n)\n    plt.semilogy(2 * mu * x / sigma**2, soln(x), label=mu)\nplt.semilogy(x, np.exp(- x), 'k')\nplt.xlim([0, 8])\nplt.ylim([1e-4,1])\nplt.xlabel(r\"$x$\")\nplt.ylabel(r\"$u_{NT}(x)$\")\n\nfig.tight_layout()\nplt.savefig(\"small_updates.png\", bbox_inches=\"tight\")\n# plt.legend()"
  },
  {
    "objectID": "decision-theory/numerical_fredholm_integral.html#scratch",
    "href": "decision-theory/numerical_fredholm_integral.html#scratch",
    "title": "Introduction",
    "section": "Scratch",
    "text": "Scratch\nAttempts at higher-order approximations, fitting the constants, etc.\n\ndef theory_nt(x, mu, sigma):\n    return (norm.cdf(-mu/sigma) / norm.cdf(mu/sigma)) * np.exp(-2 * mu * x / sigma**2)\n\ndef theory_t(x, mu, sigma):\n    a = 1 + np.abs(sigma/mu) * norm.pdf(np.abs(mu/sigma)) / norm.cdf(np.abs(mu/sigma))\n    return - (1/mu) * x + a\n\n\nmu = -2\nsigma = 1\nn = 185\n\nsoln = solve_fredholm(k(mu, sigma), f_t(), n)\n\nxmax = 6\nx = np.arange(0, xmax, 0.1)\n\nplt.plot(x, soln(x))\nplt.plot(x, theory_t(x, mu, sigma))\n# a = 1 + np.abs(sigma/mu) * norm.pdf(np.abs(mu/sigma)) / norm.cdf(np.abs(mu/sigma))\na = 1/2\nplt.plot(x, 1 - (sigma/mu)*norm.pdf((x+mu)/sigma) + (- (x/mu) + a - 1)*norm.cdf((x+mu)/sigma))\nplt.plot(x[x&lt;=-mu], 1 + norm.cdf((x[x&lt;=-mu]+mu)/sigma), ':', lw=4)\nplt.ylim([0,1 - xmax/mu])\n\n(0.0, 4.0)\n\n\n\n\n\n\ndef a_opt(x):\n    return 1/2 + 1/(2*x) - (1/x)*norm.pdf(1/2 + x/2) / norm.cdf(-(1/2 + x/2))\n\n\nmu = -1/2\nsigma = 1\nn = 185\n\nsoln = solve_fredholm(k(mu, sigma), f_t(), n)\n\nxmax = 8\nx = np.arange(0, xmax, 0.1)\n\na = 1/4\nplt.plot(x, soln(x))\nplt.plot(x, -(x/mu) + a)\nplt.plot(x, 1 - (sigma/mu)*norm.pdf((x+mu)/sigma) + (- (x/mu) + a - 1)*norm.cdf((x+mu)/sigma))\nplt.plot(x[x&lt;=-mu], 1 + norm.cdf((x[x&lt;=-mu]+mu)/sigma), ':', lw=4)\nplt.ylim([0,1 - xmax/mu])\nplt.show()\n\na = a_opt(mu/sigma)\nprint(a)\nprint(-sigma / mu * (norm.pdf(1/2) / norm.cdf(-1/2) - 1/2))\nplt.plot(x, soln(x))\nplt.plot(x, -(x/mu) + a)\nplt.plot(x, 1 - (sigma/mu)*norm.pdf((x+mu)/sigma) + (- (x/mu) + a - 1)*norm.cdf((x+mu)/sigma))\nplt.plot(x[x&lt;=-mu], 1 + norm.cdf((x[x&lt;=-mu]+mu)/sigma), ':', lw=4)\nplt.ylim([0,1 - xmax/mu])\nplt.show()\n\na = 1\nplt.plot(x, soln(x))\nplt.plot(x, -(x/mu) + a)\nplt.plot(x, 1 - (sigma/mu)*norm.pdf((x+mu)/sigma) + (- (x/mu) + a - 1)*norm.cdf((x+mu)/sigma))\nplt.plot(x[x&lt;=-mu], 1 + norm.cdf((x[x&lt;=-mu]+mu)/sigma), ':', lw=4)\nplt.ylim([0,1 - xmax/mu])\nplt.show()\n\n\n\n\n\n1.4271079588328082\n1.2821555407361296\n\n\n\n\n\n\n\n\n\nmu = -8\nsigma = 1\nn = 185\n\nsoln = solve_fredholm(k(mu, sigma), f_t(), n)\n\nxmax = 32\nx = np.arange(0, xmax, 0.1)\n\na = 1/16\nplt.plot(x, soln(x))\nplt.plot(x, -(x/mu) + a)\nplt.plot(x, 1 - (sigma/mu)*norm.pdf((x+mu)/sigma) + (- (x/mu) + a - 1)*norm.cdf((x+mu)/sigma))\nplt.plot(x[x&lt;=-mu], 1 + norm.cdf((x[x&lt;=-mu]+mu)/sigma), ':', lw=4)\nplt.vlines((-mu) / 2, 0, 1 - xmax/mu, 'k', linestyle='dashed')\nplt.ylim([0,1 - xmax/mu])\nplt.show()\n\na = 1/2\nplt.plot(x, soln(x))\nplt.plot(x, -(x/mu) + a)\nplt.plot(x, 1 - (sigma/mu)*norm.pdf((x+mu)/sigma) + (- (x/mu) + a - 1)*norm.cdf((x+mu)/sigma))\nplt.plot(x[x&lt;=-mu], 1 + norm.cdf((x[x&lt;=-mu]+mu)/sigma), ':', lw=4)\nplt.vlines((-mu) / 2, 0, 1 - xmax/mu, 'k', linestyle='dashed')\nplt.ylim([0,1 - xmax/mu])\nplt.show()\n\na = 2\nplt.plot(x, soln(x))\nplt.plot(x, -(x/mu) + a)\nplt.plot(x, 1 - (sigma/mu)*norm.pdf((x+mu)/sigma) + (- (x/mu) + a - 1)*norm.cdf((x+mu)/sigma))\nplt.plot(x[x&lt;=-mu], 1 + norm.cdf((x[x&lt;=-mu]+mu)/sigma), ':', lw=4)\nplt.vlines((-mu) / 2, 0, 1 - xmax/mu, 'k', linestyle='dashed')\nplt.ylim([0,1 - xmax/mu])\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\nmu = -4\nsigma = 1\nn = 185\n\nsoln = solve_fredholm(k(mu, sigma), f_t(), n)\n\nxmax = 12\nx = np.arange(0, xmax, 0.1)\n\na = 1/16\nplt.plot(x, soln(x))\nplt.plot(x, -(x/mu) + a)\nplt.plot(x, 1 - (sigma/mu)*norm.pdf((x+mu)/sigma) + (- (x/mu) + a - 1)*norm.cdf((x+mu)/sigma))\nplt.plot(x[x&lt;=-mu], 1 + norm.cdf((x[x&lt;=-mu]+mu)/sigma), ':', lw=4)\nplt.vlines((-mu) / 2, 0, 1 - xmax/mu, 'k', linestyle='dashed')\nplt.ylim([0,1 - xmax/mu])\nplt.show()\n\na = 1/2\nplt.plot(x, soln(x))\nplt.plot(x, -(x/mu) + a)\nplt.plot(x, 1 - (sigma/mu)*norm.pdf((x+mu)/sigma) + (- (x/mu) + a - 1)*norm.cdf((x+mu)/sigma))\nplt.plot(x[x&lt;=-mu], 1 + norm.cdf((x[x&lt;=-mu]+mu)/sigma), ':', lw=4)\nplt.vlines((-mu) / 2, 0, 1 - xmax/mu, 'k', linestyle='dashed')\nplt.ylim([0,1 - xmax/mu])\nplt.show()\n\na = 2\nplt.plot(x, soln(x))\nplt.plot(x, -(x/mu) + a)\nplt.plot(x, 1 - (sigma/mu)*norm.pdf((x+mu)/sigma) + (- (x/mu) + a - 1)*norm.cdf((x+mu)/sigma))\nplt.plot(x[x&lt;=-mu], 1 + norm.cdf((x[x&lt;=-mu]+mu)/sigma), ':', lw=4)\nplt.vlines((-mu) / 2, 0, 1 - xmax/mu, 'k', linestyle='dashed')\nplt.ylim([0,1 - xmax/mu])\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\nmu = -1/4\nsigma = 1\nn = 185\n\nsoln = solve_fredholm(k(mu, sigma), f_t(), n)\n\nxmax = 4\nx = np.arange(0, xmax, 0.01)\n\na = 1/2\nplt.plot(x, soln(x))\nplt.plot(x, -(x/mu) + a)\nplt.plot(x, 1 - (sigma/mu)*norm.pdf((x+mu)/sigma) + (- (x/mu) + a - 1)*norm.cdf((x+mu)/sigma))\nplt.ylim([0,1 - xmax/mu])\nplt.show()\n\na = 0.641 * sigma / (-mu)\nplt.plot(x, soln(x))\nplt.plot(x, -(x/mu) + a)\nplt.plot(x, 1 - (sigma/mu)*norm.pdf((x+mu)/sigma) + (- (x/mu) + a - 1)*norm.cdf((x+mu)/sigma))\nplt.ylim([0,1 - xmax/mu])\nplt.show()\n\na = 5\nplt.plot(x, soln(x))\nplt.plot(x, -(x/mu) + a)\nplt.plot(x, 1 - (sigma/mu)*norm.pdf((x+mu)/sigma) + (- (x/mu) + a - 1)*norm.cdf((x+mu)/sigma))\nplt.ylim([0,1 - xmax/mu])\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nmu = -1\nsigma = 1\nn = 185\n\nsoln = solve_fredholm(k(mu, sigma), f_t(), n)\n\nxmax = 4\nx = np.arange(0, xmax, 0.01)\n\na = 1/2\nplt.plot(x, soln(x))\nplt.plot(x, -(x/mu) + a)\nplt.plot(x, 1 - (sigma/mu)*norm.pdf((x+mu)/sigma) + (- (x/mu) + a - 1)*norm.cdf((x+mu)/sigma))\nplt.ylim([0,1 - xmax/mu])\nplt.show()\n\na = 0.9\nplt.plot(x, soln(x))\nplt.plot(x, -(x/mu) + a)\nplt.plot(x, 1 - (sigma/mu)*norm.pdf((x+mu)/sigma) + (- (x/mu) + a - 1)*norm.cdf((x+mu)/sigma))\nplt.ylim([0,1 - xmax/mu])\nplt.show()\n\na = 2\nplt.plot(x, soln(x))\nplt.plot(x, -(x/mu) + a)\nplt.plot(x, 1 - (sigma/mu)*norm.pdf((x+mu)/sigma) + (- (x/mu) + a - 1)*norm.cdf((x+mu)/sigma))\nplt.ylim([0,1 - xmax/mu])\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nmu = -4\nsigma = 1\nn = 185\n\nsoln = solve_fredholm(k(mu, sigma), f_t(), n)\n\nxmax = 12\nx = np.arange(0, xmax, 0.1)\n\nplt.plot(x, soln(x))\na = 1/2\nplt.plot(x, -(x/mu) + a)\nplt.plot(x, 1 - (sigma/mu)*norm.pdf((x+mu)/sigma) + (- (x/mu) + a - 1)*norm.cdf((x+mu)/sigma))\nplt.ylim([0,1 - xmax/mu])\n\n(0.0, 4.0)\n\n\n\n\n\n\nxmax = 32\nx = np.arange(0, xmax, 0.01)\n\nfor mu in [1/8, 1/4, 1/2, 1]:\n    a = norm.cdf(-mu / sigma)\n    soln = solve_fredholm(k(mu, sigma), f_nt(mu, sigma), n)\n    plt.semilogy(x, soln(x), label=mu)\n    plt.semilogy(x, a * np.exp(-2 * mu * x / sigma**2))\n    plt.semilogy(x, a * norm.sf(-(x+mu)/sigma) * np.exp(-2 * mu * x / sigma**2) + norm.cdf(-(x+mu)/sigma))\n    # plt.semilogy(x, np.exp(-2 * x), 'k')\n    # plt.xlim([0,4])\n    # plt.ylim([3e-3,1.1])\n    plt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmu = -1/8\nsigma = 1\nn = 185\n\nsoln = solve_fredholm(k(mu, sigma), f_t(), n)\n\nxmax = 4\nx = np.arange(0, xmax, 0.1)\n\nplt.plot(x, soln(x))\na = 2 * np.sqrt(2*np.pi)\nplt.plot(x, -(x/mu) + a)\nplt.plot(x, 1 - (sigma/mu)*norm.pdf((x+mu)/sigma) + (- (x/mu) + a - 1)*norm.cdf((x+mu)/sigma))\nplt.ylim([0,1 - xmax/mu])\n\n(0.0, 33.0)\n\n\n\n\n\n\nnp.sqrt(2*np.pi)\n\n2.5066282746310002\n\n\n\nmu = -1/4\nsigma = 1\nn = 185\n\nsoln = solve_fredholm(k(mu, sigma), f_t(), n)\n\nxmax = 4\nx = np.arange(0, xmax, 0.1)\n\nplt.plot(x, soln(x))\na = np.sqrt(2*np.pi)\nplt.plot(x, -(x/mu) + a)\nplt.plot(x, 1 - (sigma/mu)*norm.pdf((x+mu)/sigma) + (- (x/mu) + a - 1)*norm.cdf((x+mu)/sigma))\nplt.ylim([0,1 - xmax/mu])\n\n(0.0, 17.0)\n\n\n\n\n\n\nmu = -1/2\nsigma = 1\nn = 185\n\nsoln = solve_fredholm(k(mu, sigma), f_t(), n)\n\nxmax = 4\nx = np.arange(0, xmax, 0.1)\n\nplt.plot(x, soln(x))\na = np.sqrt(2*np.pi) / 2\nplt.plot(x, -(x/mu) + a)\nplt.plot(x, 1 - (sigma/mu)*norm.pdf((x+mu)/sigma) + (- (x/mu) + a - 1)*norm.cdf((x+mu)/sigma))\nplt.ylim([0,1 - xmax/mu])\n\n(0.0, 9.0)\n\n\n\n\n\n\nplt.loglog([1/2, 1/4, 1/8], [1, 2, 4], '.')\n\n\n\n\n\nmu = -1/4\nsigma = 1\nn = 185\n\nsoln = solve_fredholm(k(mu, sigma), f_t(), n)\n\nxmax = 16\nx = np.arange(0, xmax, 0.1)\n\nplt.plot(x, soln(x))\nplt.plot(x, theory_t(x, mu, sigma))\nplt.plot(x[x&lt;=-mu], 1 + norm.cdf((x[x&lt;=-mu]+mu)/sigma))\nplt.plot(x[x&gt;=-mu], -x[x&gt;=-mu]/mu + 1/2)\nplt.ylim([0,1 - xmax/mu])\n\n(0.0, 65.0)\n\n\n\n\n\n\nsigma = 1\nn = 185\nxmax = 4\nx = np.arange(0, xmax, 0.1)\n\nfor mu in [-1/2, -1/3, -1/4, -1/5]:\n    soln = solve_fredholm(k(mu, sigma), f_t(), n)\n    mod = soln(x) * -mu - x\n    plt.plot(x, mod - mod[-1])\n    # plt.plot(x, theory_t(x, mu, sigma) * -mu)\n\n\n\n\n\nmu = 2\nsigma = 1\nn = 185\n\nsoln = solve_fredholm(k(mu, sigma), f_nt(mu, sigma), n)\n\nxmax = 10\nx = np.arange(0, xmax, 0.1)\n\nplt.semilogy(x, soln(x))\n# plt.plot(x, 1 + norm.cdf((x+mu)/sigma))\n# plt.plot(x, 1 - x/mu)\nplt.semilogy(x, theory_nt(x, mu, sigma))\nplt.semilogy(x[x&lt;=mu], norm.cdf(-(x[x&lt;=mu]+mu)/sigma))\nplt.semilogy(x[x&gt;mu], np.exp(2*(mu/sigma)**2) * norm.cdf(-2*mu/sigma) * np.exp(-2*mu * x[x&gt;mu] / sigma**2))\n# plt.plot(x, -x/mu + norm.cdf(0))\n# plt.ylim([0,1 - xmax/mu])"
  },
  {
    "objectID": "air-travel/flights.html",
    "href": "air-travel/flights.html",
    "title": "Flights",
    "section": "",
    "text": "For a demonstration of a line plot on a polar axis, see Figure 1.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef integral_global(t, r, n):\n    return (np.exp(r * t) - 1) / (n * r)\n\ndef integral_local(t, r, n, f):\n    return integral_global(t, r, n) - integral_global(t, r - f, n)\n\n\n\n\nCode\nrs = [1 / 250, 1 / 800]\nfs = [1 / 300, 1 / 300]\nn = 10\nt_max = 3200\nt = np.linspace(1, t_max, t_max)\nfig, axes = plt.subplots(1, len(rs), sharey=True)\nfor r, f, ax in zip(rs, fs, axes):\n    ax.semilogy(t, integral_global(t, r, n))\n    ax.semilogy(t, integral_local(t, r, n, f))\naxes[0].set_ylim([1, 1e4])\nplt.show()\n\n\n\n\n\nFigure 1: test\n\n\n\n\n\n\nCode\nr = 1 / 60\nf = 1 / 150\nn = 10\nt_max = 300\nt = np.linspace(1, t_max, t_max)\nfig = plt.figure(figsize=(5,5))\nax = fig.add_subplot()\nax.semilogy(t, integral_global(t, r, n), label=\"Airport\")\nax.semilogy(t, integral_local(t, r, n, f), label=\"WWTP\")\nax.legend(frameon=False)\nylim = [1, 1e3]\nax.set_ylim(ylim)\nax.hlines([50], 0, 300, linestyle=\"dashed\", color=\"grey\")\nax.vlines(133, *ylim, linestyle=\"dotted\", color=\"C0\")\nax.vlines(169, *ylim, linestyle=\"dotted\", color=\"C1\")\nax.set_xlabel(\"Days since start of pandemic\")\nax.set_ylabel(\"Total reads matching virus\")\nax.text(0, 55, \"Detection threshold\", color=\"grey\")\nax.text(131, 1.1, \"Detection\\nin airport\", color=\"C0\", ha=\"right\")\n# ax.text(270, 600, \"Airport reads\", color=\"C0\", ha=\"right\")\nax.text(171, 1.1, \"Detection\\nin WWTP\", color=\"C1\")\n# ax.text(215, 100, \"WWTP reads\", color=\"C1\")\nfor spine in ['top', 'right']:\n    ax.spines[spine].set_visible(False)\nplt.show()\n\n\n\n\n\nFigure 2: test\n\n\n\n\n\n\nCode\nr = 0.259\nf = 1 / 300\nn = 1e8\nt_max = 300\nt = np.linspace(1, t_max, t_max)\nfig = plt.figure(figsize=(5,5))\nax = fig.add_subplot()\nax.semilogy(t, integral_global(t, r, n), label=\"Airport\")\nax.semilogy(t, integral_local(t, r, n, f), label=\"WWTP\")\nax.legend(frameon=False)\n# ylim = [1, 1e3]\n# ax.set_ylim(ylim)\nax.hlines([50], 0, 300, linestyle=\"dashed\", color=\"grey\")\nax.vlines(133, *ylim, linestyle=\"dotted\", color=\"C0\")\nax.vlines(169, *ylim, linestyle=\"dotted\", color=\"C1\")\nax.set_xlabel(\"Days since start of pandemic\")\nax.set_ylabel(\"Total reads matching virus\")\nax.text(0, 55, \"Detection threshold\", color=\"grey\")\nax.text(131, 1.1, \"Detection\\nin airport\", color=\"C0\", ha=\"right\")\nax.text(171, 1.1, \"Detection\\nin WWTP\", color=\"C1\")\nfor spine in ['top', 'right']:\n    ax.spines[spine].set_visible(False)\nplt.show()\n\n\n\n\n\ntest"
  },
  {
    "objectID": "flights.html",
    "href": "flights.html",
    "title": "Flights",
    "section": "",
    "text": "For a demonstration of a line plot on a polar axis, see Figure 1.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef integral_global(t, r, n):\n    return (np.exp(r * t) - 1) / (n * r)\n\ndef integral_local(t, r, n, f):\n    return integral_global(t, r, n) - integral_global(t, r - f, n)\n\n\n\n\nCode\nrs = [1 / 250, 1 / 800]\nfs = [1 / 300, 1 / 300]\nn = 10\nt_max = 3200\nt = np.linspace(1, t_max, t_max)\nfig, axes = plt.subplots(1, len(rs), sharey=True)\nfor r, f, ax in zip(rs, fs, axes):\n    ax.semilogy(t, integral_global(t, r, n))\n    ax.semilogy(t, integral_local(t, r, n, f))\naxes[0].set_ylim([1, 1e4])\nplt.show()\n\n\n\n\n\nFigure 1: test\n\n\n\n\n\n\nCode\nr = 1 / 60\nf = 1 / 150\nn = 10\nt_max = 300\nt = np.linspace(1, t_max, t_max)\nfig = plt.figure(figsize=(5,5))\nax = fig.add_subplot()\nax.semilogy(t, integral_global(t, r, n), label=\"Airport\")\nax.semilogy(t, integral_local(t, r, n, f), label=\"WWTP\")\nax.legend(frameon=False)\nylim = [1, 1e3]\nax.set_ylim(ylim)\nax.hlines([50], 0, 300, linestyle=\"dashed\", color=\"grey\")\nax.vlines(133, *ylim, linestyle=\"dotted\", color=\"C0\")\nax.vlines(169, *ylim, linestyle=\"dotted\", color=\"C1\")\nax.set_xlabel(\"Days since start of pandemic\")\nax.set_ylabel(\"Total reads matching virus\")\nax.text(0, 55, \"Detection threshold\", color=\"grey\")\nax.text(131, 1.1, \"Detection\\nin airport\", color=\"C0\", ha=\"right\")\n# ax.text(270, 600, \"Airport reads\", color=\"C0\", ha=\"right\")\nax.text(171, 1.1, \"Detection\\nin WWTP\", color=\"C1\")\n# ax.text(215, 100, \"WWTP reads\", color=\"C1\")\nfor spine in ['top', 'right']:\n    ax.spines[spine].set_visible(False)\nplt.show()\n\n\n\n\n\nFigure 2: test\n\n\n\n\n\n\nCode\nr = 0.259\nf = 1 / 300\nn = 1e8\nt_max = 300\nt = np.linspace(1, t_max, t_max)\nfig = plt.figure(figsize=(5,5))\nax = fig.add_subplot()\nax.semilogy(t, integral_global(t, r, n), label=\"Airport\")\nax.semilogy(t, integral_local(t, r, n, f), label=\"WWTP\")\nax.legend(frameon=False)\n# ylim = [1, 1e3]\n# ax.set_ylim(ylim)\nax.hlines([50], 0, 300, linestyle=\"dashed\", color=\"grey\")\nax.vlines(133, *ylim, linestyle=\"dotted\", color=\"C0\")\nax.vlines(169, *ylim, linestyle=\"dotted\", color=\"C1\")\nax.set_xlabel(\"Days since start of pandemic\")\nax.set_ylabel(\"Total reads matching virus\")\nax.text(0, 55, \"Detection threshold\", color=\"grey\")\nax.text(131, 1.1, \"Detection\\nin airport\", color=\"C0\", ha=\"right\")\nax.text(171, 1.1, \"Detection\\nin WWTP\", color=\"C1\")\nfor spine in ['top', 'right']:\n    ax.spines[spine].set_visible(False)\nplt.show()\n\n\n\n\n\ntest"
  },
  {
    "objectID": "scratch/Untitled.html",
    "href": "scratch/Untitled.html",
    "title": "",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.integrate import odeint\n\n\n\ndef func(y, t, m, r):\n    A = np.array([[r - m, 0], [m, r]])\n    return np.dot(A, y)\n\n\nt = np.arange(0, 100, 0.01)\n\nN = 1e6\nM = 1e4\nr = 0.1\ny_0 = np.array([1/N, 0])\nsoln = odeint(func, y_0, t, args=(M / N, r))\n\n\nplt.semilogy(t, soln)\n\n\n\n\n\nplt.plot(N * soln[soln[:,1] &gt; 1 / N, 0], N * soln[soln[:,1] &gt; 1 / N, 1])\n\n\n\n\n\nplt.plot(N * soln[soln[:,1] &gt; 1 / N, 0], soln[soln[:,1] &gt; 1 / N, 1] / soln[soln[:,1] &gt; 1 / N, 0])"
  },
  {
    "objectID": "CombiningData-2023-07-27.html",
    "href": "CombiningData-2023-07-27.html",
    "title": "The part we’re using",
    "section": "",
    "text": "def posterior_seq_only(p_eg, p_neg, p_eng, p_neng, p_s_e, p_s_ne):\n    return (p_s_e * p_eg) / (\n        p_s_e * p_eg + \n        p_s_ne * p_neg +\n        p_s_e * p_eng +\n        p_s_ne * p_neng\n    )\n\ndef posterior_growth_only(p_eg, p_neg, p_eng, p_neng, p_c_g, p_c_ng):\n    return (p_c_g * p_eg) / (\n        p_c_g * p_eg + \n        p_c_g * p_neg +\n        p_c_ng * p_eng +\n        p_c_ng * p_neng\n    )\n\ndef posterior_combined(p_eg, p_neg, p_eng, p_neng, p_s_e, p_s_ne, p_c_g, p_c_ng):\n    return (p_s_e * p_c_g * p_eg) / (\n        p_s_e * p_c_g * p_eg + \n        p_s_ne * p_c_g * p_neg +\n        p_s_e * p_c_ng * p_eng +\n        p_s_ne * p_c_ng * p_neng\n    )\n\nE = engineered NE = not engineered G = growing NG = not growing\nData: S = sequence is flagged C = count data is flagged\nWant posterior Pr{E, G| S} or Pr{E, G | S, C}.\nLikelihood Pr{S, C | E, G} = Pr{S | E, G} * Pr{C | E, G} = Pr{S | E} * Pr{C | G}\nLikelihood ratios: Pr{S | E} / Pr{S | NE} Pr{C | G} / Pr{C | NG}\nPrior\n\nsequences = 1e5\nthreats = 0.1\ngrowing = 1e4\n\np_eg = threats / sequences\n# Assumes anything engineered is growing\np_eng = 0.0\np_neg = (growing - threats) / sequences\np_neng = 1 - p_eg - p_eng - p_neg\n\nLikelihood\n\np_s_e = 0.9\np_s_ne = 0.2\nprint(p_s_e / p_s_ne)\np_c_g = 0.90\np_c_ng = 0.10\nprint(p_c_g / p_c_ng)\np_seq_only = posterior_seq_only(p_eg, p_neg, p_eng, p_neng, p_s_e, p_s_ne)\np_growth_only = posterior_growth_only(p_eg, p_neg, p_eng, p_neng, p_c_g, p_c_ng)\np_combined = posterior_combined(p_eg, p_neg, p_eng, p_neng, p_s_e, p_s_ne, p_c_g, p_c_ng)\nprint(p_seq_only)\nprint(p_growth_only)\nprint(p_combined)\n\n4.5\n9.0\n4.499984250055124e-06\n4.9999999999999996e-06\n2.24996062568905e-05\n\n\n\np_s_e = 0.9\np_s_ne = 0.05\nposterior_seq_only(p_eg, p_neg, p_eng, p_neng, p_s_e, p_s_ne)\n\n1.7999694005201907e-05\n\n\nBase rates (assume the threat is growing):\n\nsequences = 1e6\nthreats = 1\ngrowing = 1e4\n\nLikelihoods of the Sequence-based test:\n\n# Pr{S|E}\np_s_e = 0.99\n# Pr{S|NE}\np_s_ne = 0.1\n\nFalse and true positives of Sequence-based test alone:\n\n# Number flagged not threats\nprint(p_s_ne * (sequences - threats))\n# Number flagged that are threats\nprint(p_s_e * (threats))\n\n99999.90000000001\n0.99\n\n\nLikelihoods of the Count-based test:\n\n# Pr{C|G}\np_c_g = 0.95\n# Pr{C|NG}\np_c_ng = 0.05\n\n\n# Number flagged not threats\nprint(p_c_g * (growing - threats))\nprint(p_c_ng * (sequences - growing))\n# Number flagged that are threats\nprint(p_c_g * threats)\n\n9499.05\n49500.0\n0.95\n\n\nCombined test (assumes flagging by the two tests is independent conditional on (E, G))\n\n# Number flagged not threats\nprint(p_s_ne * p_c_g * (growing - threats) + p_s_ne * p_c_ng * (sequences - growing))\n# Number flagged threats\nprint(p_s_e * p_c_g * threats)\n\n5899.905000000001\n0.9405"
  },
  {
    "objectID": "2023-08-18_SimplePrevalence.html",
    "href": "2023-08-18_SimplePrevalence.html",
    "title": "Simple deterministic model of local and global prevalence",
    "section": "",
    "text": "This is building on Mike’s notes. The objective is to have a very simple deterministic model of an exponentially-growing virus spreading from somewhere else in the world to a monitored city. The main difference from Mike’s notes is that our flight model conserves the number of people who are infected.\nSome assumptions:"
  },
  {
    "objectID": "2023-08-18_SimplePrevalence.html#dynamics",
    "href": "2023-08-18_SimplePrevalence.html#dynamics",
    "title": "Simple deterministic model of local and global prevalence",
    "section": "Dynamics",
    "text": "Dynamics\nWe’ll use the variable \\(P\\) to be the absolute prevalence, i.e. the raw number of people infected, and \\(p\\) to be the relative prevalence, i.e., the fraction of a given population that is infected. The subscript \\(l\\) refers to the local population of the monitored city and \\(nl\\) refers to the non-local population. We use the subscript \\(g\\) to refer to the total. So \\(P_{g}\\) is the total number of people currently infected.\nParameters:\n\n\\(r\\), the exponential growth rate per day of the virus\n\\(f_{in}\\), the rate per person per day of flying to the focal city\n\\(f_{out}\\), the rate per person per day of flying out of the focal city\n\\(N_l\\), \\(N_{nl}\\), \\(N_g\\), the local, non-local and global population sizes\n\nOur model is a pair of ODEs (dots represent time derivatives):\n\\[\n\\dot{P}_{nl} = (r - f_{in}) P_{nl} + f_{out} P_l\n\\]\n\\[\n\\dot{P}_{l} = f_{in} P_{nl} + (r - f_{out}) P_l\n\\]\nwith initial conditions \\(P_{nl}(0) = 1\\) and \\(P_{l}(0) = 0\\).\n(An aside about the initial conditions. While it’s reasonable to model a virus that starts by infecting one individual, it is not accurate to extend the deterministic model to the earliest stages of the pandemic. In particular, the early stages will be both noisy and superexponential because conditional on not going extinct the prevalence has to grow quickly to get away from the zero bound. In the medium-term – after stochastic effects dominate and before saturation sets in – the prevalence will grow approximately exponentially. You can think of this model as extrapolating that regime backwards in time to an “effective time zero”. One thing to check is whether this causes any problems for the local dynamics.)\nNote that our flight model conserves the total prevalence: the rate of infected individuals flying from global to local is exactly equal to the reverse rate. Thus, we have exponential growth of the global prevalence:\n\\[\nP_{g} \\equiv P_{nl} + P_{l}\n\\]\n\\[\n\\dot{P}_{g} = r P_{g}\n\\]\nWe have found one eigenvector of the system of ODEs. The other takes on a natural meaning if we make a further assumption about the rates of flights. We assume that the rate of flying to the focal city is proportional to its size. In particular, we set \\(N_{nl} f_{in} = N_l f_{out}\\). With this assumption, some algebra shows that the second eigenvector is the difference between the non-local and local prevalence:\n\\[\n\\Delta p \\equiv p_{nl} - p_l\n\\]\n\\[\n\\dot{\\Delta p} = (r - F) \\Delta p\n\\]\nwhere \\(F \\equiv f_{in} + f_{out}\\). Note that if \\(N_{l} \\ll N_{nl}\\) then \\(F \\approx f_{out}\\), the rate at which people fly from the focal city every day.\nThis equation shows that there are two regimes:\n\nIn the slow-growth regime: \\(r &lt; F\\), \\(\\Delta p\\) shrinks exponentially at rate \\(F - r\\). Mixing via air travel closes the gap between the local and non-local prevalence.\nIn the fast-growth regime: \\(r &gt; F\\), \\(\\Delta p\\) grows exponentially at rate \\(r - F\\). The local prevalence will never catch up with the non-local prevalence until saturation effects slow the non-local spread (which is outside the scope of this model).\n\nIn the slow-growth regime, there’s no intrinsic advantage to monitoring air travelers (aside from whatever sample properties like fewer non-human contributions to the wastewater) because the virus gets established locally before it reaches high prevalence globally. Of course this conclusion depends on our simple model: having a more detailed model of the flight network may suggest that there are particular places it would be good to monitor. Also, stochastic effects may matter a lot in this regime, because it relies on establishment of the virus locally from a small number of introductions.\nIn the fast-growth regime, there may be a significant advantage to monitoring air travelers if it’s possible to catch the virus while it’s in it’s exponential phase globally. We would need a non-linear model with saturation effects (e.g. Charlie’s) to estimate the advantage if we can’t catch it while it’s growing exponentially."
  },
  {
    "objectID": "2023-08-18_SimplePrevalence.html#scratch",
    "href": "2023-08-18_SimplePrevalence.html#scratch",
    "title": "Simple deterministic model of local and global prevalence",
    "section": "Scratch",
    "text": "Scratch\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef integral_global(t, r, n):\n    return (np.exp(r * t) - 1) / (n * r)\n\ndef integral_local(t, r, n, f):\n    return integral_global(t, r, n) - integral_global(t, r - f, n)\n\n\n\n\nCode\nrs = [1 / 250, 1 / 800]\nfs = [1 / 300, 1 / 300]\nn = 10\nt_max = 3200\nt = np.linspace(1, t_max, t_max)\nfig, axes = plt.subplots(1, len(rs), sharey=True)\nfor r, f, ax in zip(rs, fs, axes):\n    ax.semilogy(t, integral_global(t, r, n))\n    ax.semilogy(t, integral_local(t, r, n, f))\naxes[0].set_ylim([1, 1e4])\nplt.show()\n\n\n\n\n\nFigure 1: test\n\n\n\n\n\n\nCode\nr = 1 / 60\nf = 1 / 150\nn = 10\nt_max = 300\nt = np.linspace(1, t_max, t_max)\nfig = plt.figure(figsize=(5,5))\nax = fig.add_subplot()\nax.semilogy(t, integral_global(t, r, n), label=\"Airport\")\nax.semilogy(t, integral_local(t, r, n, f), label=\"WWTP\")\nax.legend(frameon=False)\nylim = [1, 1e3]\nax.set_ylim(ylim)\nax.hlines([50], 0, 300, linestyle=\"dashed\", color=\"grey\")\nax.vlines(133, *ylim, linestyle=\"dotted\", color=\"C0\")\nax.vlines(169, *ylim, linestyle=\"dotted\", color=\"C1\")\nax.set_xlabel(\"Days since start of pandemic\")\nax.set_ylabel(\"Total reads matching virus\")\nax.text(0, 55, \"Detection threshold\", color=\"grey\")\nax.text(131, 1.1, \"Detection\\nin airport\", color=\"C0\", ha=\"right\")\n# ax.text(270, 600, \"Airport reads\", color=\"C0\", ha=\"right\")\nax.text(171, 1.1, \"Detection\\nin WWTP\", color=\"C1\")\n# ax.text(215, 100, \"WWTP reads\", color=\"C1\")\nfor spine in ['top', 'right']:\n    ax.spines[spine].set_visible(False)\nplt.show()\n\n\n\n\n\nFigure 2: test\n\n\n\n\n\n\nCode\nr = 0.259\nf = 1 / 300\nn = 1e8\nt_max = 300\nt = np.linspace(1, t_max, t_max)\nfig = plt.figure(figsize=(5,5))\nax = fig.add_subplot()\nax.semilogy(t, integral_global(t, r, n), label=\"Airport\")\nax.semilogy(t, integral_local(t, r, n, f), label=\"WWTP\")\nax.legend(frameon=False)\n# ylim = [1, 1e3]\n# ax.set_ylim(ylim)\nax.hlines([50], 0, 300, linestyle=\"dashed\", color=\"grey\")\nax.vlines(133, *ylim, linestyle=\"dotted\", color=\"C0\")\nax.vlines(169, *ylim, linestyle=\"dotted\", color=\"C1\")\nax.set_xlabel(\"Days since start of pandemic\")\nax.set_ylabel(\"Total reads matching virus\")\nax.text(0, 55, \"Detection threshold\", color=\"grey\")\nax.text(131, 1.1, \"Detection\\nin airport\", color=\"C0\", ha=\"right\")\nax.text(171, 1.1, \"Detection\\nin WWTP\", color=\"C1\")\nfor spine in ['top', 'right']:\n    ax.spines[spine].set_visible(False)\nplt.show()\n\n\n\n\n\ntest"
  },
  {
    "objectID": "2023-08-18_SimplePrevalence.html#monitoring-in-the-fast",
    "href": "2023-08-18_SimplePrevalence.html#monitoring-in-the-fast",
    "title": "Simple deterministic model of local and global prevalence",
    "section": "Monitoring in the fast",
    "text": "Monitoring in the fast"
  },
  {
    "objectID": "2023-08-18_SimplePrevalence.html#monitoring-in-the-fast-growth-regime",
    "href": "2023-08-18_SimplePrevalence.html#monitoring-in-the-fast-growth-regime",
    "title": "Simple deterministic model of local and global prevalence",
    "section": "Monitoring in the fast-growth regime",
    "text": "Monitoring in the fast-growth regime\nCharlie estimates that \\(F \\approx 1 / 300\\) (a person flies on average once every 300 days). This paper says that the doubling time of SARS-CoV-2 in the US before mitigation efforts was 2.68 days (\\(r = 0.26\\)). Thus, for a covid-like spread, we might expect \\(r / F \\sim 80\\). In this section, we consider monitoring for such a pathogen in the fast-growth regime where \\(r \\gg F\\).\nSolving our differential equations, we have:\n\\[\np_g = \\frac{1}{N_g} e^{rt}\n\\]\n\\[\np_l = \\frac{1}{N_l} \\frac{f_{in}}{F} \\left( 1 - e^{-Ft} \\right) e^{r t}\n    \\approx \\frac{1}{N_g} \\left( 1 - e^{-Ft} \\right) e^{r t}\n\\]\nThe global population is 8 billion people, so we can get a crude upper bound on the time our model will be valid for by solving for when exponential growth would infect everyone:\n\n\nCode\nimport numpy as np\ndoubling_time = 2.68\nr = np.log(2) / doubling_time\nn_g = 8e9\nsaturation_time = np.log(n_g) / r\nprint(f\"Saturation time: {saturation_time:0.2f} days\")\n\n\nSaturation time: 88.16 days\n\n\nThis is several times shorter than the mixing time \\(1 / F\\), so it’s safe to simplify our equation to:\n\\[\np_l \\approx \\frac{1}{N_g} Ft e^{r t}\n\\]\nSo in short times the ratio \\[\n\\frac{p_l}{p_g} \\approx Ft\n\\]\n\nCumulative reads\nWe assume that the cumulative reads are proportional to the time integral of the prevalence:\n\\[\n\\int_0^t p_g dt = \\frac{1}{rN_g} (e^{rt} - 1) \\approx \\frac{1}{rN_g} e^{rt}\n\\]\n\\[\n\\int_0^t p_l dt = \\frac{F}{r^2N_g} \\left(e^{rt} (rt - 1) + 1\\right)\n\\approx \\frac{1}{rN_g} Ft e^{rt}\n\\]\nTo be continued…"
  },
  {
    "objectID": "2023-08-18_SimplePrevalence.html#scratch-disregard",
    "href": "2023-08-18_SimplePrevalence.html#scratch-disregard",
    "title": "Simple deterministic model of local and global prevalence",
    "section": "Scratch (disregard)",
    "text": "Scratch (disregard)\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef integral_global(t, r, n):\n    return (np.exp(r * t) - 1) / (n * r)\n\ndef integral_local(t, r, n, f):\n    return integral_global(t, r, n) - integral_global(t, r - f, n)\n\n\n\n\nCode\nrs = [1 / 250, 1 / 800]\nfs = [1 / 300, 1 / 300]\nn = 10\nt_max = 3200\nt = np.linspace(1, t_max, t_max)\nfig, axes = plt.subplots(1, len(rs), sharey=True)\nfor r, f, ax in zip(rs, fs, axes):\n    ax.semilogy(t, integral_global(t, r, n))\n    ax.semilogy(t, integral_local(t, r, n, f))\naxes[0].set_ylim([1, 1e4])\nplt.show()\n\n\n\n\n\nFigure 1: test\n\n\n\n\n\n\nCode\nr = 1 / 60\nf = 1 / 150\nn = 10\nt_max = 300\nt = np.linspace(1, t_max, t_max)\nfig = plt.figure(figsize=(5,5))\nax = fig.add_subplot()\nax.semilogy(t, integral_global(t, r, n), label=\"Airport\")\nax.semilogy(t, integral_local(t, r, n, f), label=\"WWTP\")\nax.legend(frameon=False)\nylim = [1, 1e3]\nax.set_ylim(ylim)\nax.hlines([50], 0, 300, linestyle=\"dashed\", color=\"grey\")\nax.vlines(133, *ylim, linestyle=\"dotted\", color=\"C0\")\nax.vlines(169, *ylim, linestyle=\"dotted\", color=\"C1\")\nax.set_xlabel(\"Days since start of pandemic\")\nax.set_ylabel(\"Total reads matching virus\")\nax.text(0, 55, \"Detection threshold\", color=\"grey\")\nax.text(131, 1.1, \"Detection\\nin airport\", color=\"C0\", ha=\"right\")\n# ax.text(270, 600, \"Airport reads\", color=\"C0\", ha=\"right\")\nax.text(171, 1.1, \"Detection\\nin WWTP\", color=\"C1\")\n# ax.text(215, 100, \"WWTP reads\", color=\"C1\")\nfor spine in ['top', 'right']:\n    ax.spines[spine].set_visible(False)\nplt.show()\n\n\n\n\n\nFigure 2: test\n\n\n\n\n\n\nCode\nr = 0.259\nf = 1 / 300\nn = 1e8\nt_max = 300\nt = np.linspace(1, t_max, t_max)\nfig = plt.figure(figsize=(5,5))\nax = fig.add_subplot()\nax.semilogy(t, integral_global(t, r, n), label=\"Airport\")\nax.semilogy(t, integral_local(t, r, n, f), label=\"WWTP\")\nax.legend(frameon=False)\n# ylim = [1, 1e3]\n# ax.set_ylim(ylim)\nax.hlines([50], 0, 300, linestyle=\"dashed\", color=\"grey\")\nax.vlines(133, *ylim, linestyle=\"dotted\", color=\"C0\")\nax.vlines(169, *ylim, linestyle=\"dotted\", color=\"C1\")\nax.set_xlabel(\"Days since start of pandemic\")\nax.set_ylabel(\"Total reads matching virus\")\nax.text(0, 55, \"Detection threshold\", color=\"grey\")\nax.text(131, 1.1, \"Detection\\nin airport\", color=\"C0\", ha=\"right\")\nax.text(171, 1.1, \"Detection\\nin WWTP\", color=\"C1\")\nfor spine in ['top', 'right']:\n    ax.spines[spine].set_visible(False)\nplt.show()\n\n\n\n\n\ntest"
  },
  {
    "objectID": "2023-08-29-qpcr_analysis.html",
    "href": "2023-08-29-qpcr_analysis.html",
    "title": "2023-08-29 qPCR Analysis",
    "section": "",
    "text": "Compare several wastewater filtering options by measuring the nucleic acid content by qPCR. Experimental design here.\nGet Dan up to speed with working with this data.\nExplore options for data analysis workflows."
  },
  {
    "objectID": "2023-08-29-qpcr_analysis.html#objectives",
    "href": "2023-08-29-qpcr_analysis.html#objectives",
    "title": "2023-08-29 qPCR Analysis",
    "section": "",
    "text": "Compare several wastewater filtering options by measuring the nucleic acid content by qPCR. Experimental design here.\nGet Dan up to speed with working with this data.\nExplore options for data analysis workflows."
  },
  {
    "objectID": "2023-08-29-qpcr_analysis.html#preliminary-work",
    "href": "2023-08-29-qpcr_analysis.html#preliminary-work",
    "title": "2023-08-29 qPCR Analysis",
    "section": "Preliminary work",
    "text": "Preliminary work\n\nAri put the .eds files into Google Drive from the lab computer. (He also exported some Excel files but we’re not using those.)\nDan installed the Google Drive desktop app and Design and Analysis on his Mac, opened the .eds files, and fixed some missing data in the plate layout\nDan used the “Analyze” in Design and Analysis to automatically calculate thresholds and compute c_q values.\nDan exported the data to .csv.\nSymlinked the google drive folder for the airport experiment to ~/airport/ on his computer so I don’t have to refer to the whole filepath here."
  },
  {
    "objectID": "2023-08-29-qpcr_analysis.html#data-import",
    "href": "2023-08-29-qpcr_analysis.html#data-import",
    "title": "2023-08-29 qPCR Analysis",
    "section": "Data import",
    "text": "Data import\n\nlibrary(readr)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(purrr)\n\ndata_dir &lt;- \"~/airport/[2023-08-29] CP Prefilters vs Vacuum Filters/Test 1 qPCR Results/csv/\"\nfilename_pattern &lt;- \"Results\"\n\n\nraw_data &lt;- list.files(\n                       data_dir,\n                       pattern = filename_pattern,\n                       full.names = TRUE\n                       ) |&gt;\n  map(function(f) read_csv(f, skip=23)) |&gt;\n  list_rbind()\n\nRows: 36 Columns: 21\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (8): Well Position, Sample, Target, Task, Reporter, Quencher, Amp Status...\ndbl (8): Well, Amp Score, Cq Confidence, Cq Mean, Cq SD, Threshold, Baseline...\nlgl (5): Omit, Curve Quality, Result Quality Issues, Auto Threshold, Auto Ba...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 29 Columns: 21\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (8): Well Position, Sample, Target, Task, Reporter, Quencher, Amp Status...\ndbl (8): Well, Amp Score, Cq Confidence, Cq Mean, Cq SD, Threshold, Baseline...\nlgl (5): Omit, Curve Quality, Result Quality Issues, Auto Threshold, Auto Ba...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nprint(raw_data)\n\n# A tibble: 65 × 21\n    Well `Well Position` Omit  Sample Target Task    Reporter Quencher\n   &lt;dbl&gt; &lt;chr&gt;           &lt;lgl&gt; &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt;   &lt;chr&gt;    &lt;chr&gt;   \n 1     1 A1              FALSE 1      CrA    UNKNOWN FAM      NFQ-MGB \n 2     2 A2              FALSE 1      CrA    UNKNOWN FAM      NFQ-MGB \n 3     3 A3              FALSE 1      CrA    UNKNOWN FAM      NFQ-MGB \n 4     5 A5              FALSE 1      16S    UNKNOWN FAM      NFQ-MGB \n 5     6 A6              FALSE 1      16S    UNKNOWN FAM      NFQ-MGB \n 6     7 A7              FALSE 1      16S    UNKNOWN FAM      NFQ-MGB \n 7    13 B1              FALSE 2      CrA    UNKNOWN FAM      NFQ-MGB \n 8    14 B2              FALSE 2      CrA    UNKNOWN FAM      NFQ-MGB \n 9    15 B3              FALSE 2      CrA    UNKNOWN FAM      NFQ-MGB \n10    17 B5              FALSE 2      16S    UNKNOWN FAM      NFQ-MGB \n# ℹ 55 more rows\n# ℹ 13 more variables: `Amp Status` &lt;chr&gt;, `Amp Score` &lt;dbl&gt;,\n#   `Curve Quality` &lt;lgl&gt;, `Result Quality Issues` &lt;lgl&gt;, Cq &lt;chr&gt;,\n#   `Cq Confidence` &lt;dbl&gt;, `Cq Mean` &lt;dbl&gt;, `Cq SD` &lt;dbl&gt;,\n#   `Auto Threshold` &lt;lgl&gt;, Threshold &lt;dbl&gt;, `Auto Baseline` &lt;lgl&gt;,\n#   `Baseline Start` &lt;dbl&gt;, `Baseline End` &lt;dbl&gt;\n\n\n\ncoding = list(\n  \"1\" = \"Normal centrifugation/filtration, regular CP\",\n  \"2\" = \"Normal centrifugation/filtration, regular CP\",\n  \"3\" = \"Normal centrifugation, no filtration, prefilter CP\",\n  \"4\" = \"Normal centrifugation, no filtration, prefilter CP\",\n  \"5\" = \"No centrifugation/filtration, prefilter CP\",\n  \"6\" = \"No centrifugation/filtration, prefilter CP\"\n)\ntidy_data &lt;- raw_data |&gt;\n  mutate(\n    Cq = as.double(Cq),\n    Sample = recode(Sample, !!!coding)\n  )\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `Cq = as.double(Cq)`.\nCaused by warning:\n! NAs introduced by coercion\n\n\n\nlibrary(ggplot2)\ntidy_data |&gt;\n  ggplot(mapping = aes(x=Cq, y=Sample)) +\n  geom_point() +\n  facet_wrap(facets = ~Target)\n\nWarning: Removed 11 rows containing missing values (`geom_point()`)."
  },
  {
    "objectID": "2023-08-29-qpcr_analysis.html#todo",
    "href": "2023-08-29-qpcr_analysis.html#todo",
    "title": "2023-08-29 qPCR Analysis",
    "section": "TODO",
    "text": "TODO\n\nFigure out what the Sample numbers mean with respect to the different treatments\nThere are a few NaNs that show up as missing points and aren’t evident in the plot. Will investigate later."
  },
  {
    "objectID": "2023-09-08_SequencingCosts.html",
    "href": "2023-09-08_SequencingCosts.html",
    "title": "Airport experiment sequencing cost estimate",
    "section": "",
    "text": "We are planning to sequence samples from four sources (redacted because this is publicly visible). We will receive one sample from each source each day weekday for eight weeks. Thus we will have \\(8 \\times 5 \\times 4 = 160\\) samples total.\nWe will the following steps ourselves:\nThen we will deliver the RNA extracts to the BioMicroCenter for library prep and sequencing on an Illumina NovaSeq 6000. The goal of this doc is to estimate the cost of library prep and sequencing."
  },
  {
    "objectID": "2023-09-08_SequencingCosts.html#sources",
    "href": "2023-09-08_SequencingCosts.html#sources",
    "title": "Airport experiment sequencing cost estimate",
    "section": "Sources",
    "text": "Sources\n\nThe cost of library prep and sequencing come from the BioMicroCenter’s pricing page. We use the MIT prices.\nCharacteristics of the NovaSeq come from illumina (Table 1)."
  },
  {
    "objectID": "2023-09-08_SequencingCosts.html#estimate",
    "href": "2023-09-08_SequencingCosts.html#estimate",
    "title": "Airport experiment sequencing cost estimate",
    "section": "Estimate",
    "text": "Estimate\nEach NovaSeq flow cell has 4 lanes. When run in 2 x 150 bp mode, it generates 150 basepair forward and reverse read pairs for 300 bp per read pair. In one run, the flow cell generates 2400–3000 Gb of data. In the following we will make a conservative estimate by using the lower end of the range.\n\nlanes_per_flow_cell = 4\nbp_per_read_pair = 300\ngb_per_flow_cell = 2400\n\nread_pairs_per_flow_cell = gb_per_flow_cell * 1e9 / bp_per_read_pair\nread_pairs_per_lane = read_pairs_per_flow_cell / lanes_per_flow_cell\nprint(f\"We expect at least {read_pairs_per_lane/1e6} M read pairs per lane\")\n\nWe expect at least 2000.0 M read pairs per lane\n\n\nThe smallest unit of NovaSeq sequencing we can buy is one lane, which costs $5,940. We also pay $258.5 per sample for library preparation.\n\ncost_per_lane = 5940\nlibrary_cost_per_sample = 258.5\n\nWe’ll consider three options:\n\nSequencing all 160 samples in 4 lanes\nSequencing all 160 samples in 8 lanes\nSequencing MWF only (\\(160 \\times 3/5 = 96\\) samples) in 5 lanes\n\n\nfor num_samples, num_lanes in [(160, 4), (160, 8), (96, 5)]:\n    samples_per_lane = num_samples / num_lanes\n    read_pairs_per_sample = read_pairs_per_lane / samples_per_lane\n    sequencing_cost = cost_per_lane * num_lanes\n    library_cost = library_cost_per_sample * num_samples\n    total_cost = sequencing_cost + library_cost\n    cost_per_sample = total_cost / num_samples\n    cost_per_read_pair = cost_per_sample / read_pairs_per_sample\n    print(f\"\"\"\n    {num_samples} samples in {num_lanes} lanes:\n        Million read pairs per sample:\\t{read_pairs_per_sample / 1e6:3,.0f}\n        Sequencing cost:\\t${sequencing_cost:7,.0f} \n        Library prep cost:\\t${library_cost:7,.0f}\n        Total cost:\\t\\t\\t${total_cost:7,.0f}\n        Cost per sample:\\t${cost_per_sample:7,.0f}\n        Cost per M rp:\\t\\t${cost_per_read_pair * 1e6:10.2f}\n    \"\"\")\n\n\n    160 samples in 4 lanes:\n        Million read pairs per sample:   50\n        Sequencing cost:    $ 23,760 \n        Library prep cost:  $ 41,360\n        Total cost:         $ 65,120\n        Cost per sample:    $    407\n        Cost per M rp:      $      8.14\n    \n\n    160 samples in 8 lanes:\n        Million read pairs per sample:  100\n        Sequencing cost:    $ 47,520 \n        Library prep cost:  $ 41,360\n        Total cost:         $ 88,880\n        Cost per sample:    $    556\n        Cost per M rp:      $      5.56\n    \n\n    96 samples in 5 lanes:\n        Million read pairs per sample:  104\n        Sequencing cost:    $ 29,700 \n        Library prep cost:  $ 24,816\n        Total cost:         $ 54,516\n        Cost per sample:    $    568\n        Cost per M rp:      $      5.45"
  }
]