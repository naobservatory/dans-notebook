[
  {
    "objectID": "notebooks/2023-08-18_SimplePrevalence.html",
    "href": "notebooks/2023-08-18_SimplePrevalence.html",
    "title": "Simple deterministic model of local and global prevalence",
    "section": "",
    "text": "This is building on Mike’s notes. The objective is to have a very simple deterministic model of an exponentially-growing virus spreading from somewhere else in the world to a monitored city. The main difference from Mike’s notes is that our flight model conserves the number of people who are infected.\nSome assumptions:"
  },
  {
    "objectID": "notebooks/2023-08-18_SimplePrevalence.html#dynamics",
    "href": "notebooks/2023-08-18_SimplePrevalence.html#dynamics",
    "title": "Simple deterministic model of local and global prevalence",
    "section": "Dynamics",
    "text": "Dynamics\nWe’ll use the variable \\(P\\) to be the absolute prevalence, i.e. the raw number of people infected, and \\(p\\) to be the relative prevalence, i.e., the fraction of a given population that is infected. The subscript \\(l\\) refers to the local population of the monitored city and \\(nl\\) refers to the non-local population. We use the subscript \\(g\\) to refer to the total. So \\(P_{g}\\) is the total number of people currently infected.\nParameters:\n\n\\(r\\), the exponential growth rate per day of the virus\n\\(f_{in}\\), the rate per person per day of flying to the focal city\n\\(f_{out}\\), the rate per person per day of flying out of the focal city\n\\(N_l\\), \\(N_{nl}\\), \\(N_g\\), the local, non-local and global population sizes\n\nOur model is a pair of ODEs (dots represent time derivatives):\n\\[\n\\dot{P}_{nl} = (r - f_{in}) P_{nl} + f_{out} P_l\n\\]\n\\[\n\\dot{P}_{l} = f_{in} P_{nl} + (r - f_{out}) P_l\n\\]\nwith initial conditions \\(P_{nl}(0) = 1\\) and \\(P_{l}(0) = 0\\).\n(An aside about the initial conditions. While it’s reasonable to model a virus that starts by infecting one individual, it is not accurate to extend the deterministic model to the earliest stages of the pandemic. In particular, the early stages will be both noisy and superexponential because conditional on not going extinct the prevalence has to grow quickly to get away from the zero bound. In the medium-term – after stochastic effects dominate and before saturation sets in – the prevalence will grow approximately exponentially. You can think of this model as extrapolating that regime backwards in time to an “effective time zero”. One thing to check is whether this causes any problems for the local dynamics.)\nNote that our flight model conserves the total prevalence: the rate of infected individuals flying from global to local is exactly equal to the reverse rate. Thus, we have exponential growth of the global prevalence:\n\\[\nP_{g} \\equiv P_{nl} + P_{l}\n\\]\n\\[\n\\dot{P}_{g} = r P_{g}\n\\]\nWe have found one eigenvector of the system of ODEs. The other takes on a natural meaning if we make a further assumption about the rates of flights. We assume that the rate of flying to the focal city is proportional to its size. In particular, we set \\(N_{nl} f_{in} = N_l f_{out}\\). With this assumption, some algebra shows that the second eigenvector is the difference between the non-local and local prevalence:\n\\[\n\\Delta p \\equiv p_{nl} - p_l\n\\]\n\\[\n\\dot{\\Delta p} = (r - F) \\Delta p\n\\]\nwhere \\(F \\equiv f_{in} + f_{out}\\). Note that if \\(N_{l} \\ll N_{nl}\\) then \\(F \\approx f_{out}\\), the rate at which people fly from the focal city every day.\nThis equation shows that there are two regimes:\n\nIn the slow-growth regime: \\(r &lt; F\\), \\(\\Delta p\\) shrinks exponentially at rate \\(F - r\\). Mixing via air travel closes the gap between the local and non-local prevalence.\nIn the fast-growth regime: \\(r &gt; F\\), \\(\\Delta p\\) grows exponentially at rate \\(r - F\\). The local prevalence will never catch up with the non-local prevalence until saturation effects slow the non-local spread (which is outside the scope of this model).\n\nIn the slow-growth regime, there’s no intrinsic advantage to monitoring air travelers (aside from whatever sample properties like fewer non-human contributions to the wastewater) because the virus gets established locally before it reaches high prevalence globally. Of course this conclusion depends on our simple model: having a more detailed model of the flight network may suggest that there are particular places it would be good to monitor. Also, stochastic effects may matter a lot in this regime, because it relies on establishment of the virus locally from a small number of introductions.\nIn the fast-growth regime, there may be a significant advantage to monitoring air travelers if it’s possible to catch the virus while it’s in it’s exponential phase globally. We would need a non-linear model with saturation effects (e.g. Charlie’s) to estimate the advantage if we can’t catch it while it’s growing exponentially."
  },
  {
    "objectID": "notebooks/2023-08-18_SimplePrevalence.html#monitoring-in-the-fast-growth-regime",
    "href": "notebooks/2023-08-18_SimplePrevalence.html#monitoring-in-the-fast-growth-regime",
    "title": "Simple deterministic model of local and global prevalence",
    "section": "Monitoring in the fast-growth regime",
    "text": "Monitoring in the fast-growth regime\nCharlie estimates that \\(F \\approx 1 / 300\\) (a person flies on average once every 300 days). This paper says that the doubling time of SARS-CoV-2 in the US before mitigation efforts was 2.68 days (\\(r = 0.26\\)). Thus, for a covid-like spread, we might expect \\(r / F \\sim 80\\). In this section, we consider monitoring for such a pathogen in the fast-growth regime where \\(r \\gg F\\).\nSolving our differential equations, we have:\n\\[\np_g = \\frac{1}{N_g} e^{rt}\n\\]\n\\[\np_l = \\frac{1}{N_l} \\frac{f_{in}}{F} \\left( 1 - e^{-Ft} \\right) e^{r t}\n    \\approx \\frac{1}{N_g} \\left( 1 - e^{-Ft} \\right) e^{r t}\n\\]\nThe global population is 8 billion people, so we can get a crude upper bound on the time our model will be valid for by solving for when exponential growth would infect everyone:\n\n\nCode\nimport numpy as np\ndoubling_time = 2.68\nr = np.log(2) / doubling_time\nn_g = 8e9\nsaturation_time = np.log(n_g) / r\nprint(f\"Saturation time: {saturation_time:0.2f} days\")\n\n\nSaturation time: 88.16 days\n\n\nThis is several times shorter than the mixing time \\(1 / F\\), so it’s safe to simplify our equation to:\n\\[\np_l \\approx \\frac{1}{N_g} Ft e^{r t}\n\\]\nSo in short times the ratio \\[\n\\frac{p_l}{p_g} \\approx Ft\n\\]\n\nCumulative reads\nWe assume that the cumulative reads are proportional to the time integral of the prevalence:\n\\[\n\\int_0^t p_g dt = \\frac{1}{rN_g} (e^{rt} - 1) \\approx \\frac{1}{rN_g} e^{rt}\n\\]\n\\[\n\\int_0^t p_l dt = \\frac{F}{r^2N_g} \\left(e^{rt} (rt - 1) + 1\\right)\n\\approx \\frac{1}{rN_g} Ft e^{rt}\n\\]\nTo be continued…"
  },
  {
    "objectID": "notebooks/2023-08-18_SimplePrevalence.html#scratch-disregard",
    "href": "notebooks/2023-08-18_SimplePrevalence.html#scratch-disregard",
    "title": "Simple deterministic model of local and global prevalence",
    "section": "Scratch (disregard)",
    "text": "Scratch (disregard)\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef integral_global(t, r, n):\n    return (np.exp(r * t) - 1) / (n * r)\n\ndef integral_local(t, r, n, f):\n    return integral_global(t, r, n) - integral_global(t, r - f, n)\n\n\n\n\nCode\nrs = [1 / 250, 1 / 800]\nfs = [1 / 300, 1 / 300]\nn = 10\nt_max = 3200\nt = np.linspace(1, t_max, t_max)\nfig, axes = plt.subplots(1, len(rs), sharey=True)\nfor r, f, ax in zip(rs, fs, axes):\n    ax.semilogy(t, integral_global(t, r, n))\n    ax.semilogy(t, integral_local(t, r, n, f))\naxes[0].set_ylim([1, 1e4])\nplt.show()\n\n\n\n\n\nFigure 1: test\n\n\n\n\n\n\nCode\nr = 1 / 60\nf = 1 / 150\nn = 10\nt_max = 300\nt = np.linspace(1, t_max, t_max)\nfig = plt.figure(figsize=(5,5))\nax = fig.add_subplot()\nax.semilogy(t, integral_global(t, r, n), label=\"Airport\")\nax.semilogy(t, integral_local(t, r, n, f), label=\"WWTP\")\nax.legend(frameon=False)\nylim = [1, 1e3]\nax.set_ylim(ylim)\nax.hlines([50], 0, 300, linestyle=\"dashed\", color=\"grey\")\nax.vlines(133, *ylim, linestyle=\"dotted\", color=\"C0\")\nax.vlines(169, *ylim, linestyle=\"dotted\", color=\"C1\")\nax.set_xlabel(\"Days since start of pandemic\")\nax.set_ylabel(\"Total reads matching virus\")\nax.text(0, 55, \"Detection threshold\", color=\"grey\")\nax.text(131, 1.1, \"Detection\\nin airport\", color=\"C0\", ha=\"right\")\n# ax.text(270, 600, \"Airport reads\", color=\"C0\", ha=\"right\")\nax.text(171, 1.1, \"Detection\\nin WWTP\", color=\"C1\")\n# ax.text(215, 100, \"WWTP reads\", color=\"C1\")\nfor spine in ['top', 'right']:\n    ax.spines[spine].set_visible(False)\nplt.show()\n\n\n\n\n\nFigure 2: test\n\n\n\n\n\n\nCode\nr = 0.259\nf = 1 / 300\nn = 1e8\nt_max = 300\nt = np.linspace(1, t_max, t_max)\nfig = plt.figure(figsize=(5,5))\nax = fig.add_subplot()\nax.semilogy(t, integral_global(t, r, n), label=\"Airport\")\nax.semilogy(t, integral_local(t, r, n, f), label=\"WWTP\")\nax.legend(frameon=False)\n# ylim = [1, 1e3]\n# ax.set_ylim(ylim)\nax.hlines([50], 0, 300, linestyle=\"dashed\", color=\"grey\")\nax.vlines(133, *ylim, linestyle=\"dotted\", color=\"C0\")\nax.vlines(169, *ylim, linestyle=\"dotted\", color=\"C1\")\nax.set_xlabel(\"Days since start of pandemic\")\nax.set_ylabel(\"Total reads matching virus\")\nax.text(0, 55, \"Detection threshold\", color=\"grey\")\nax.text(131, 1.1, \"Detection\\nin airport\", color=\"C0\", ha=\"right\")\nax.text(171, 1.1, \"Detection\\nin WWTP\", color=\"C1\")\nfor spine in ['top', 'right']:\n    ax.spines[spine].set_visible(False)\nplt.show()\n\n\n\n\n\ntest"
  },
  {
    "objectID": "notebooks/2023-07-18_ExtractionKitEvaluation.html",
    "href": "notebooks/2023-07-18_ExtractionKitEvaluation.html",
    "title": "Examine extraction-kit comparison experiment",
    "section": "",
    "text": "Drive folder"
  },
  {
    "objectID": "notebooks/2023-07-18_ExtractionKitEvaluation.html#metadata",
    "href": "notebooks/2023-07-18_ExtractionKitEvaluation.html#metadata",
    "title": "Examine extraction-kit comparison experiment",
    "section": "metadata",
    "text": "metadata\n\nmeta_samples &lt;- path(data_path, 'qpcr', 'meta_samples.csv') %&gt;%\n  read_csv %&gt;%\n  rename(sample_qpcr = sample_qPCR) %&gt;%\n  janitor::clean_names() %&gt;%\n  glimpse\n\nRows: 27 Columns: 8\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (7): sample_qPCR, Kit, treatment_group, LPA, other_treatment, Virus_spec...\ndbl (1): group\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nRows: 27\nColumns: 8\n$ sample_qpcr     &lt;chr&gt; \"1_ZR_A\", \"1_ZR_B\", \"1_ZR_C\", \"2_ZDR_A\", \"2_ZDR_B\", \"2…\n$ kit             &lt;chr&gt; \"Zymo RNA\", \"Zymo RNA\", \"Zymo RNA\", \"Zymo RNA/DNA\", \"Z…\n$ treatment_group &lt;chr&gt; \"ZQ-RNA\", \"ZQ-RNA\", \"ZQ-RNA\", \"ZQ-RNADNA\", \"ZQ-RNADNA\"…\n$ lpa             &lt;chr&gt; \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", …\n$ group           &lt;dbl&gt; 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ other_treatment &lt;chr&gt; \"Shield\", \"Shield\", \"Shield\", \"Shield\", \"Shield\", \"Shi…\n$ virus_specific  &lt;chr&gt; \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"No\", \"No\", …\n$ fp_data         &lt;chr&gt; \"No\", \"Yes\", \"No\", \"No\", \"Yes\", \"No\", \"No\", \"Yes\", \"No…\n\nmeta_targets &lt;- path(data_path, 'qpcr', 'meta_target.csv') %&gt;%\n  read_csv %&gt;%\n  rename(target_qpcr = target_qPCR) %&gt;%\n  janitor::clean_names() %&gt;%\n  glimpse\n\nRows: 5 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): target_qPCR, target\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nRows: 5\nColumns: 2\n$ target_qpcr &lt;chr&gt; \"CrA\", \"Cov2\", \"Noro\", \"16S\", \"Phg\"\n$ target      &lt;chr&gt; \"Crassphage\", \"SARS-CoV-2\", \"Norovirus\", \"bacteria\", \"phag…"
  },
  {
    "objectID": "notebooks/2023-07-18_ExtractionKitEvaluation.html#qpcr",
    "href": "notebooks/2023-07-18_ExtractionKitEvaluation.html#qpcr",
    "title": "Examine extraction-kit comparison experiment",
    "section": "qPCR",
    "text": "qPCR\n\nfns &lt;- data_path %&gt;%\n  dir_ls(recurse = TRUE, glob = '*_Standard Curve Result_*.csv')\nfns %&gt;% path_file\n\n[1] \"2023-07-26_Cov2-kits_Standard Curve Result_20230728 133121.csv\"    \n[2] \"2023-07-26_CrA-kits_Standard Curve Result_20230728 135806.csv\"     \n[3] \"2023-07-26_Noro_kits_Standard Curve Result_20230728 140336.csv\"    \n[4] \"2023-07-26_Phagemid-kits_Standard Curve Result_20230728 141050.csv\"\n\n\n\nresults_raw &lt;- tibble(file = fns) %&gt;%\n  mutate(.keep = 'unused',\n    data = map(file, read_qpcr_results_csv)\n  ) %&gt;%\n  unnest(data)\n\n\nresults &lt;- results_raw %&gt;%\n  rename(target_qpcr = target) %&gt;%\n  left_join(meta_samples, by = c('sample' = 'sample_qpcr')) %&gt;%\n  left_join(meta_targets, by = 'target_qpcr') %&gt;%\n  mutate(\n  )\n\n\namp curves\n\nfns_amp &lt;- data_path %&gt;%\n  dir_ls(recurse = TRUE, glob = '*_Amplification Data_*.csv') %&gt;%\n  str_subset(negate = TRUE, 'Raw')\n\namp1 &lt;- tibble(file = fns_amp) %&gt;%\n  mutate(.keep = 'unused',\n    data = map(file, read_qpcr_amplification_csv)\n  ) %&gt;%\n  unnest(data) %&gt;%\n  rename(target_qpcr = target) %&gt;%\n  left_join(results)\n\nJoining with `by = join_by(well, well_position, row, column, target_qpcr,\nsample, omit)`\n\n\n\n\nSecond experiment\n\ndata_path2 &lt;- here('_data/2023-07-13-volume-and-dilution')\n\nmeta_samples2 &lt;- path(data_path2, 'qpcr', 'meta_samples.csv') %&gt;%\n  read_csv %&gt;%\n  rename(sample_qpcr = sample_qPCR) %&gt;%\n  janitor::clean_names()\n\nRows: 6 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): sample_qPCR, treatment_group\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nmeta_targets2 &lt;- path(data_path2, 'qpcr', 'meta_target.csv') %&gt;%\n  read_csv %&gt;%\n  rename(target_qpcr = target_qPCR) %&gt;%\n  janitor::clean_names()\n\nRows: 4 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): target_qPCR, target\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nfns2 &lt;- data_path2 %&gt;%\n  dir_ls(recurse = TRUE, glob = '*_Standard Curve Result_*.csv')\nfns2 %&gt;% path_file\n\n[1] \"2023-07-20_SSTweenCovNoro_Standard Curve Result_20230724 143043.csv\"\n[2] \"2023-07-20_TweenCrA16S_Standard Curve Result_20230724 142856.csv\"   \n\nresults_raw2 &lt;- tibble(file = fns2) %&gt;%\n  mutate(.keep = 'unused',\n    data = map(file, read_qpcr_results_csv)\n  ) %&gt;%\n  unnest(data)\n\nresults2 &lt;- results_raw2 %&gt;%\n  rename(target_qpcr = target) %&gt;%\n  left_join(meta_samples2, by = c('sample' = 'sample_qpcr')) %&gt;%\n  left_join(meta_targets2, by = 'target_qpcr') %&gt;%\n  mutate(\n  )\n\nfns_amp2 &lt;- data_path2 %&gt;%\n  dir_ls(recurse = TRUE, glob = '*_Amplification Data_*.csv') %&gt;%\n  str_subset(negate = TRUE, 'Raw')\n\namp2 &lt;- tibble(file = fns_amp2) %&gt;%\n  mutate(.keep = 'unused',\n    data = map(file, read_qpcr_amplification_csv)\n  ) %&gt;%\n  unnest(data) %&gt;%\n  rename(target_qpcr = target) %&gt;%\n  left_join(results2)\n\nJoining with `by = join_by(well, well_position, row, column, target_qpcr,\nsample, omit)`\n\n\n\ndata_path3 &lt;- here('_data/2023-06-13-concentration')\n\nmeta_samples3 &lt;- path(data_path3, 'qpcr', 'meta_samples.csv') %&gt;%\n  read_csv %&gt;%\n  mutate(treatment_group=as.character(treatment_group)) %&gt;%\n  # rename(sample_qpcr = sample_qPCR) %&gt;%\n  janitor::clean_names()\n\nRows: 12 Columns: 9\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): sample_qpcr, filter, sewer_system, method, method_short\ndbl (4): treatment_group, sample_number, volume, amicon_mwco\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nmeta_targets3 &lt;- path(data_path3, 'qpcr', 'meta_target.csv') %&gt;%\n  read_csv %&gt;%\n  rename(target_qpcr = target_qPCR) %&gt;%\n  janitor::clean_names()\n\nRows: 5 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): target_qPCR, target\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nfns3 &lt;- data_path3 %&gt;%\n  dir_ls(recurse = TRUE, glob = '*_Standard Curve Result_*.csv')\nfns3 %&gt;% path_file\n\n[1] \"2023-06-23_CPAmicon_16S_Standard Curve Result_20230625 111656.csv\"    \n[2] \"2023-06-23_AmiconCP-COVNORO_Standard Curve Result_20230623 171728.csv\"\n[3] \"2023-06-23_CrAPhg_Standard Curve Result_20230623 171458.csv\"          \n\nresults_raw3 &lt;- tibble(file = fns3) %&gt;%\n  mutate(.keep = 'unused',\n    data = map(file, read_qpcr_results_csv)\n  ) %&gt;%\n  unnest(data)\nprint(unique(results_raw3$sample))\n\n [1] \"N_30\"               \"N_0.05-80\"          \"6840.0\"            \n [4] \"N_100\"              \"N_Ultra-80\"         \"684.0\"             \n [7] \"N_0.05\"             \"S_0.05-80\"          \"68.4\"              \n[10] \"N_Ultra\"            \"S_Ultra-80\"         \"6.840000000000001\" \n[13] \"S_30\"               NA                   \"0.6840000000000002\"\n[16] \"S_100\"              \"S_0.05\"             \"S_Ultra\"           \n[19] \"10.0\"               \"100000.0\"           \"10000.0\"           \n[22] \"1000.0\"             \"100.0\"             \n\nprint(unique(results_raw3$target))\n\n[1] \"16S\"  \"Cov2\" \"Noro\" \"CrA\"  \"phg\" \n\nresults3 &lt;- results_raw3 %&gt;%\n  rename(target_qpcr = target) %&gt;%\n  left_join(meta_samples3, by = c('sample' = 'sample_qpcr')) %&gt;%\n  left_join(meta_targets3, by = 'target_qpcr') %&gt;%\n  mutate(\n  )\n\nfns_amp3 &lt;- data_path3 %&gt;%\n  dir_ls(recurse = TRUE, glob = '*_Amplification Data_*.csv') %&gt;%\n  str_subset(negate = TRUE, 'Raw')\n\n\namp3 &lt;- tibble(file = fns_amp3) %&gt;%\n  mutate(.keep = 'unused',\n    data = map(file, read_qpcr_amplification_csv)\n  ) %&gt;%\n  unnest(data) %&gt;%\n  rename(target_qpcr = target) %&gt;%\n  left_join(results3)\n\nJoining with `by = join_by(well, well_position, row, column, target_qpcr,\nsample, omit)`\n\n\n\namp1$experiment &lt;- 1\namp2$experiment &lt;- 2\namp3$experiment &lt;- 3\namp &lt;- bind_rows(amp1, amp2, amp3)\n# amp &lt;- bind_rows(amp1, amp2)"
  },
  {
    "objectID": "notebooks/2023-07-18_ExtractionKitEvaluation.html#inspect-sars2-amplification-curves",
    "href": "notebooks/2023-07-18_ExtractionKitEvaluation.html#inspect-sars2-amplification-curves",
    "title": "Examine extraction-kit comparison experiment",
    "section": "Inspect SARS2 amplification curves",
    "text": "Inspect SARS2 amplification curves\n\ndelta_rn_min &lt;- 1e-3\nct_threshold &lt;- results %&gt;% filter(target == 'SARS-CoV-2') %&gt;% pull(threshold) %&gt;% unique\nstopifnot(length(ct_threshold) == 1)\n\namp %&gt;%\n  filter(\n    target == 'SARS-CoV-2',\n    !is.na(treatment_group)\n  ) %&gt;%\n  ggplot(aes(cycle_number, pmax(d_rn, delta_rn_min), color = treatment_group)) +\n  # scale_color_manual(values = colors_oi %&gt;% unname) +\n  scale_y_log10() +\n  geom_line(aes(group = well)) +\n  geom_hline(yintercept = ct_threshold, alpha = 0.3) +\n  facet_wrap(~experiment) +\n  # scale_color_brewer(type = 'qual') +\n  # geom_point(data = baselines, aes(shape = baseline_boundary), size = 3) +\n  # scale_shape_manual(values = c(1, 4)) +\n  labs(y = 'Delta Rn', x = 'Cycle', color = 'Target')\n\n\n\n\n\namp %&gt;%\n  filter(\n    target == 'SARS-CoV-2',\n    task %in% c('STANDARD', 'UNKNOWN')\n  ) %&gt;%\n  ggplot(aes(cycle_number, pmax(d_rn, delta_rn_min), color = treatment_group)) +\n  facet_wrap(~treatment_group) +\n  # scale_color_manual(values = colors_oi %&gt;% unname) +\n  scale_x_continuous(limits = c(25, 40)) +\n  scale_y_log10() +\n  geom_line(aes(group = well)) +\n  geom_hline(yintercept = ct_threshold, alpha = 0.3) +\n  labs(y = 'Delta Rn', x = 'Cycle', color = 'Target')\n\nWarning: Removed 2064 rows containing missing values (`geom_line()`).\n\n\n\n\n\n\namp %&gt;%\n  filter(\n    target == 'SARS-CoV-2',\n    task == 'STANDARD'\n  ) %&gt;%\n  ggplot(aes(cycle_number, pmax(d_rn, delta_rn_min), color = sample)) +\n  # scale_color_manual(values = colors_oi %&gt;% unname) +\n  # scale_x_continuous(limits = c(25, 40)) +\n  scale_y_log10() +\n  geom_line(aes(group = well)) +\n  geom_hline(yintercept = ct_threshold, alpha = 0.3) +\n  labs(y = 'Delta Rn', x = 'Cycle', color = 'Target')\n\n\n\n\n\nCheck SC versus target samples\n\namp %&gt;%\n  filter(\n    target == 'SARS-CoV-2',\n    task %in% c('STANDARD', 'UNKNOWN')\n  ) %&gt;%\n  ggplot(aes(cycle_number, pmax(d_rn, delta_rn_min), color = interaction(task, experiment))) +\n  scale_color_manual(values = colors_oi %&gt;% unname) +\n  scale_x_continuous(limits = c(15, 40)) +\n  scale_y_log10() +\n  geom_line(aes(group = interaction(well, experiment))) +\n  geom_hline(yintercept = ct_threshold, alpha = 0.3) +\n  labs(y = 'Delta Rn', x = 'Cycle', color = 'Target')\n\nWarning: Removed 1960 rows containing missing values (`geom_line()`).\n\n\n\n\n\n\namp %&gt;%\n  filter(\n    # target == 'SARS-CoV-2',\n    task %in% c('STANDARD', 'UNKNOWN')\n  ) %&gt;%\n  ggplot(aes(cycle_number, pmax(d_rn, delta_rn_min), color = interaction(task, experiment))) +\n  facet_wrap(~target) + \n  scale_color_manual(values = colors_oi %&gt;% unname) +\n  scale_x_continuous(limits = c(15, 40)) +\n  scale_y_log10() +\n  geom_line(aes(group = interaction(well, experiment))) +\n  geom_hline(yintercept = ct_threshold, alpha = 0.3) +\n  labs(y = 'Delta Rn', x = 'Cycle', color = 'Target')\n\nWarning: Removed 3220 rows containing missing values (`geom_line()`)."
  },
  {
    "objectID": "notebooks/2023-08-29-qpcr_analysis.html",
    "href": "notebooks/2023-08-29-qpcr_analysis.html",
    "title": "2023-08-29 qPCR Analysis",
    "section": "",
    "text": "Compare several wastewater filtering options by measuring the nucleic acid content by qPCR. Experimental design here.\nGet Dan up to speed with working with this data.\nExplore options for data analysis workflows."
  },
  {
    "objectID": "notebooks/2023-08-29-qpcr_analysis.html#objectives",
    "href": "notebooks/2023-08-29-qpcr_analysis.html#objectives",
    "title": "2023-08-29 qPCR Analysis",
    "section": "",
    "text": "Compare several wastewater filtering options by measuring the nucleic acid content by qPCR. Experimental design here.\nGet Dan up to speed with working with this data.\nExplore options for data analysis workflows."
  },
  {
    "objectID": "notebooks/2023-08-29-qpcr_analysis.html#preliminary-work",
    "href": "notebooks/2023-08-29-qpcr_analysis.html#preliminary-work",
    "title": "2023-08-29 qPCR Analysis",
    "section": "Preliminary work",
    "text": "Preliminary work\n\nAri put the .eds files into Google Drive from the lab computer. (He also exported some Excel files but we’re not using those.)\nDan installed the Google Drive desktop app and Design and Analysis on his Mac, opened the .eds files, and fixed some missing data in the plate layout\nDan used the “Analyze” in Design and Analysis to automatically calculate thresholds and compute c_q values.\nDan exported the data to .csv.\nSymlinked the google drive folder for the airport experiment to ~/airport/ on his computer so I don’t have to refer to the whole filepath here."
  },
  {
    "objectID": "notebooks/2023-08-29-qpcr_analysis.html#data-import",
    "href": "notebooks/2023-08-29-qpcr_analysis.html#data-import",
    "title": "2023-08-29 qPCR Analysis",
    "section": "Data import",
    "text": "Data import\n\nlibrary(readr)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(purrr)\n\ndata_dir &lt;- \"~/airport/[2023-08-29] CP Prefilters vs Vacuum Filters/Test 1 qPCR Results/csv/\"\nfilename_pattern &lt;- \"Results\"\n\n\nraw_data &lt;- list.files(\n                       data_dir,\n                       pattern = filename_pattern,\n                       full.names = TRUE\n                       ) |&gt;\n  map(function(f) read_csv(f, skip=23)) |&gt;\n  list_rbind()\n\nRows: 36 Columns: 21\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (8): Well Position, Sample, Target, Task, Reporter, Quencher, Amp Status...\ndbl (8): Well, Amp Score, Cq Confidence, Cq Mean, Cq SD, Threshold, Baseline...\nlgl (5): Omit, Curve Quality, Result Quality Issues, Auto Threshold, Auto Ba...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 29 Columns: 21\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (8): Well Position, Sample, Target, Task, Reporter, Quencher, Amp Status...\ndbl (8): Well, Amp Score, Cq Confidence, Cq Mean, Cq SD, Threshold, Baseline...\nlgl (5): Omit, Curve Quality, Result Quality Issues, Auto Threshold, Auto Ba...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nprint(raw_data)\n\n# A tibble: 65 × 21\n    Well `Well Position` Omit  Sample Target Task    Reporter Quencher\n   &lt;dbl&gt; &lt;chr&gt;           &lt;lgl&gt; &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt;   &lt;chr&gt;    &lt;chr&gt;   \n 1     1 A1              FALSE 1      CrA    UNKNOWN FAM      NFQ-MGB \n 2     2 A2              FALSE 1      CrA    UNKNOWN FAM      NFQ-MGB \n 3     3 A3              FALSE 1      CrA    UNKNOWN FAM      NFQ-MGB \n 4     5 A5              FALSE 1      16S    UNKNOWN FAM      NFQ-MGB \n 5     6 A6              FALSE 1      16S    UNKNOWN FAM      NFQ-MGB \n 6     7 A7              FALSE 1      16S    UNKNOWN FAM      NFQ-MGB \n 7    13 B1              FALSE 2      CrA    UNKNOWN FAM      NFQ-MGB \n 8    14 B2              FALSE 2      CrA    UNKNOWN FAM      NFQ-MGB \n 9    15 B3              FALSE 2      CrA    UNKNOWN FAM      NFQ-MGB \n10    17 B5              FALSE 2      16S    UNKNOWN FAM      NFQ-MGB \n# ℹ 55 more rows\n# ℹ 13 more variables: `Amp Status` &lt;chr&gt;, `Amp Score` &lt;dbl&gt;,\n#   `Curve Quality` &lt;lgl&gt;, `Result Quality Issues` &lt;lgl&gt;, Cq &lt;chr&gt;,\n#   `Cq Confidence` &lt;dbl&gt;, `Cq Mean` &lt;dbl&gt;, `Cq SD` &lt;dbl&gt;,\n#   `Auto Threshold` &lt;lgl&gt;, Threshold &lt;dbl&gt;, `Auto Baseline` &lt;lgl&gt;,\n#   `Baseline Start` &lt;dbl&gt;, `Baseline End` &lt;dbl&gt;\n\n\n\ncoding = list(\n  \"1\" = \"Normal centrifugation/filtration, regular CP\",\n  \"2\" = \"Normal centrifugation/filtration, regular CP\",\n  \"3\" = \"Normal centrifugation, no filtration, prefilter CP\",\n  \"4\" = \"Normal centrifugation, no filtration, prefilter CP\",\n  \"5\" = \"No centrifugation/filtration, prefilter CP\",\n  \"6\" = \"No centrifugation/filtration, prefilter CP\"\n)\ntidy_data &lt;- raw_data |&gt;\n  mutate(\n    Cq = as.double(Cq),\n    Treatment = recode(Sample, !!!coding)\n  )\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `Cq = as.double(Cq)`.\nCaused by warning:\n! NAs introduced by coercion\n\n\n\nlibrary(ggplot2)\ntidy_data |&gt;\n  ggplot(mapping = aes(x=Cq, y=Treatment, color=Sample)) +\n  geom_point(alpha=0.5) +\n  facet_wrap(facets = ~Target)\n\nWarning: Removed 11 rows containing missing values (`geom_point()`)."
  },
  {
    "objectID": "notebooks/2023-08-29-qpcr_analysis.html#todo",
    "href": "notebooks/2023-08-29-qpcr_analysis.html#todo",
    "title": "2023-08-29 qPCR Analysis",
    "section": "TODO",
    "text": "TODO\n\nFigure out what the Sample numbers mean with respect to the different treatments\nThere are a few NaNs that show up as missing points and aren’t evident in the plot. Will investigate later."
  },
  {
    "objectID": "CombiningData-2023-07-27.html",
    "href": "CombiningData-2023-07-27.html",
    "title": "The part we’re using",
    "section": "",
    "text": "def posterior_seq_only(p_eg, p_neg, p_eng, p_neng, p_s_e, p_s_ne):\n    return (p_s_e * p_eg) / (\n        p_s_e * p_eg + \n        p_s_ne * p_neg +\n        p_s_e * p_eng +\n        p_s_ne * p_neng\n    )\n\ndef posterior_growth_only(p_eg, p_neg, p_eng, p_neng, p_c_g, p_c_ng):\n    return (p_c_g * p_eg) / (\n        p_c_g * p_eg + \n        p_c_g * p_neg +\n        p_c_ng * p_eng +\n        p_c_ng * p_neng\n    )\n\ndef posterior_combined(p_eg, p_neg, p_eng, p_neng, p_s_e, p_s_ne, p_c_g, p_c_ng):\n    return (p_s_e * p_c_g * p_eg) / (\n        p_s_e * p_c_g * p_eg + \n        p_s_ne * p_c_g * p_neg +\n        p_s_e * p_c_ng * p_eng +\n        p_s_ne * p_c_ng * p_neng\n    )\n\nE = engineered NE = not engineered G = growing NG = not growing\nData: S = sequence is flagged C = count data is flagged\nWant posterior Pr{E, G| S} or Pr{E, G | S, C}.\nLikelihood Pr{S, C | E, G} = Pr{S | E, G} * Pr{C | E, G} = Pr{S | E} * Pr{C | G}\nLikelihood ratios: Pr{S | E} / Pr{S | NE} Pr{C | G} / Pr{C | NG}\nPrior\n\nsequences = 1e5\nthreats = 0.1\ngrowing = 1e4\n\np_eg = threats / sequences\n# Assumes anything engineered is growing\np_eng = 0.0\np_neg = (growing - threats) / sequences\np_neng = 1 - p_eg - p_eng - p_neg\n\nLikelihood\n\np_s_e = 0.9\np_s_ne = 0.2\nprint(p_s_e / p_s_ne)\np_c_g = 0.90\np_c_ng = 0.10\nprint(p_c_g / p_c_ng)\np_seq_only = posterior_seq_only(p_eg, p_neg, p_eng, p_neng, p_s_e, p_s_ne)\np_growth_only = posterior_growth_only(p_eg, p_neg, p_eng, p_neng, p_c_g, p_c_ng)\np_combined = posterior_combined(p_eg, p_neg, p_eng, p_neng, p_s_e, p_s_ne, p_c_g, p_c_ng)\nprint(p_seq_only)\nprint(p_growth_only)\nprint(p_combined)\n\n4.5\n9.0\n4.499984250055124e-06\n4.9999999999999996e-06\n2.24996062568905e-05\n\n\n\np_s_e = 0.9\np_s_ne = 0.05\nposterior_seq_only(p_eg, p_neg, p_eng, p_neng, p_s_e, p_s_ne)\n\n1.7999694005201907e-05\n\n\nBase rates (assume the threat is growing):\n\nsequences = 1e6\nthreats = 1\ngrowing = 1e4\n\nLikelihoods of the Sequence-based test:\n\n# Pr{S|E}\np_s_e = 0.99\n# Pr{S|NE}\np_s_ne = 0.1\n\nFalse and true positives of Sequence-based test alone:\n\n# Number flagged not threats\nprint(p_s_ne * (sequences - threats))\n# Number flagged that are threats\nprint(p_s_e * (threats))\n\n99999.90000000001\n0.99\n\n\nLikelihoods of the Count-based test:\n\n# Pr{C|G}\np_c_g = 0.95\n# Pr{C|NG}\np_c_ng = 0.05\n\n\n# Number flagged not threats\nprint(p_c_g * (growing - threats))\nprint(p_c_ng * (sequences - growing))\n# Number flagged that are threats\nprint(p_c_g * threats)\n\n9499.05\n49500.0\n0.95\n\n\nCombined test (assumes flagging by the two tests is independent conditional on (E, G))\n\n# Number flagged not threats\nprint(p_s_ne * p_c_g * (growing - threats) + p_s_ne * p_c_ng * (sequences - growing))\n# Number flagged threats\nprint(p_s_e * p_c_g * threats)\n\n5899.905000000001\n0.9405"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Dan’s NAO Notebook",
    "section": "",
    "text": "Examine extraction-kit comparison experiment\n\n\n\n\n\n\n\n\n\n\n\n\nSep 18, 2023\n\n\nDan Rice\n\n\n\n\n\n\n  \n\n\n\n\n2023-09-13 Extraction Experiment 2 qPCR Analysis\n\n\n\n\n\n\n\n\n\n\n\n\nSep 15, 2023\n\n\nDan Rice\n\n\n\n\n\n\n  \n\n\n\n\nAirport experiment sequencing cost estimate\n\n\n\n\n\n\n\n\n\n\n\n\nSep 8, 2023\n\n\nDan Rice\n\n\n\n\n\n\n  \n\n\n\n\n2023-08-29 qPCR Analysis\n\n\n\n\n\n\n\n\n\n\n\n\nAug 29, 2023\n\n\nDan Rice\n\n\n\n\n\n\n  \n\n\n\n\nSimple deterministic model of local and global prevalence\n\n\n\n\n\n\n\n\n\n\n\n\nAug 16, 2023\n\n\nDan Rice\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "decision-theory/numerical_fredholm_integral.html",
    "href": "decision-theory/numerical_fredholm_integral.html",
    "title": "Introduction",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom numpy.polynomial.laguerre import laggauss\nfrom numpy import linalg\nfrom scipy.stats import norm\nWe want to solve a Fredholm integral equation of the second kind, of the form:\n\\(u(x) = \\int_{0}^{\\infty} K(x, t) u(t) dt + f(x)\\)\nWe’ll approach it by using Gauss-Laguerre quadrature to approximate the integral (note that we have to insert \\(\\exp(t)\\) to cancel the implicit \\(\\exp(-t)\\) weighting function of the G-L quadrature.):\n\\(u(x) \\approx \\sum_{j=1}^{n} w_j \\exp(t_j) K(x, t_j) u(t_j) + f(x)\\)\nIf we evaluate \\(u\\) at the quadrature points (\\(u_i = u(x_i)\\)), we get a linear system:\n\\(u_i \\approx \\sum_{j=1}^{n} w_j \\exp(x_j) K(x_i, x_j) u_j + f(x_i)\\)\nIn matrix form, we have:\n\\(A \\vec{u} = \\vec{b}\\)\n\\(A_{i,j} = \\delta_{i,j} - w_j exp(x_j) K(x_i, x_j)\\)\n\\(b_i = f(x_i)\\)\nWe can solve this for \\(\\vec{u}\\). Then to get the continuous function \\(u(x)\\), we can substitute \\(\\vec{u}\\) into the right-hand side of the approximation above:\n\\(u(x) \\approx \\sum_{j=1}^{n} w_j \\exp(t_j) K(x, t_j) u_j + f(x)\\)\ndef solve_fredholm(k, f, n):\n    x, w = laggauss(n)\n    A = np.eye(n) - w * np.exp(x) * k(x[:,None], x)\n    b = f(x)\n    u = linalg.solve(A, b)\n    def soln(y):\n        return np.dot(w * np.exp(x) * k(y[:,None], x), u) + f(y)\n    return soln\ndef k(mu, sigma):\n    return lambda x, t: norm(loc=mu, scale=sigma).pdf(t - x)\n\ndef f_nt(mu, sigma):\n    return norm(loc=-mu, scale=sigma).sf\n\ndef f_t():\n    return np.ones_like\nAs we increase the number of nodes, we approach the asymptotic behavior (in \\(x\\)) that we expect from theory.\nmu = 1\nsigma = 1\n\nxmax = 5\nx = np.arange(0, xmax, 0.01)\n\nfor n in [5, 10, 20]:\n    plt.plot(x, solve_fredholm(k(-mu, sigma), f_t(), n)(x), label = f\"n = {n}\")\nplt.plot(x, x / mu + 1, 'k--', label=\"asymptotic theory\")\nplt.legend(frameon=False)\nplt.xlabel(r\"$x$\")\nplt.ylabel(r\"$u_T(x)$\")\nplt.show()\n\nfor n in [5, 10, 20]:\n    plt.semilogy(x, solve_fredholm(k(mu, sigma), f_nt(mu, sigma), n)(x), label = f\"n = {n}\")\nplt.plot(x, norm.cdf(-mu/sigma) * np.exp(-2 * mu * x / sigma**2), 'k--', label=\"asymptotic theory\")\nplt.legend(frameon=False)\nplt.xlabel(r\"$x$\")\nplt.ylabel(r\"$u_{NT}(x)$\")\nplt.show()"
  },
  {
    "objectID": "decision-theory/numerical_fredholm_integral.html#scaling-diagrams",
    "href": "decision-theory/numerical_fredholm_integral.html#scaling-diagrams",
    "title": "Introduction",
    "section": "Scaling diagrams",
    "text": "Scaling diagrams\n\nn = 185\nsigma = 1\n\n\nThreat, \\(|\\mu / \\sigma| \\ge 1\\)\n\nxmax = 32\nx = np.arange(0, xmax, 0.01)\n\nfor mu in [-1, -2, -4, -8]:\n    soln = solve_fredholm(k(mu, sigma), f_t(), n)\n    plt.plot(x / (-mu), soln(x), label=mu)\nplt.plot(x, x + 0.5, 'k')\nplt.xlim([0, 4])\nplt.ylim([0, 5])\nplt.xlabel(r\"$x / (-\\mu)$\")\nplt.ylabel(r\"$u(x)$\")\nplt.legend()\n\n&lt;matplotlib.legend.Legend at 0x126fa1f90&gt;\n\n\n\n\n\n\nxmax = 16\nx = np.arange(0, xmax, 0.01)\n\nplt.figure(figsize=(3,2))\nfor mu in [-4, -8]:\n    soln = solve_fredholm(k(mu, sigma), f_t(), n)\n    plt.plot(x, soln(x), label=r\"$\\tau = $\" + f\"{-2 * mu}\")\nplt.xlim([0, xmax])\nplt.ylim([0, 5])\nplt.xlabel(r\"$x$\")\nplt.ylabel(r\"$u_T(x)$\")\nplt.legend(frameon=False)\nplt.savefig(\"large_updates.png\", bbox_inches=\"tight\")\n\n\n\n\n\n\nNon-threat, \\(|\\mu / \\sigma| \\ge 1\\)\nOne term from the Liouville-Neumann series:\n\nfor mu in [1, 2, 3, 4]:\n    xmax = 2*mu\n    x = np.arange(0, xmax, 0.01)\n\n    soln = solve_fredholm(k(mu, sigma), f_nt(mu, sigma), n)\n    plt.semilogy(x / mu, soln(x), label=mu)\n    plt.semilogy(x / mu, norm.cdf(-(x+mu)/sigma))\n    plt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\nMultiple terms from the Liouville-Neumann series:\n\nfor mu in [1, 2, 3, 4]:\n    xmax = 2*mu\n    x = np.arange(0, xmax, 0.01)\n\n    soln = solve_fredholm(k(mu, sigma), f_nt(mu, sigma), n)\n    approx = np.zeros_like(x)\n    for j in range(1, 4):\n        approx += norm.cdf(-(x + j * mu)/(np.sqrt(j) * sigma))\n    plt.semilogy(x / mu, soln(x), label=mu)\n    plt.semilogy(x / mu, approx)\n    plt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNon-threat, \\(|\\mu / \\sigma| \\leq 1\\)\n\nxmax = 32\nx = np.arange(0, xmax, 0.01)\n\nfor mu in [1/8, 1/4, 1/2, 1]:\n    soln = solve_fredholm(k(mu, sigma), f_nt(mu, sigma), n)\n    plt.semilogy(2 * mu * x / sigma**2, soln(x), label=mu)\nplt.semilogy(x, np.exp(- x), 'k')\nplt.xlim([0, 8])\nplt.ylim([1e-4,1])\nplt.xlabel(r\"$2 \\mu x / \\sigma^2$\")\nplt.ylabel(r\"$u(x)$\")\nplt.legend()\n\n&lt;matplotlib.legend.Legend at 0x126fbac10&gt;\n\n\n\n\n\nTesting the hypothesis that \\(u_{NT}(0) \\sim \\frac{1}{1 + \\sqrt{\\tau/2}}\\) for \\(\\tau \\to 0\\).\n\nplt.subplot(211)\nfor mu in np.logspace(-1.5, 0, 20):\n    soln = solve_fredholm(k(mu, sigma), f_nt(mu, sigma), n)\n    plt.loglog(mu, 1 - soln(np.zeros(1)), '.k')\n    plt.loglog(mu, 1 - 1 / (1 + np.sqrt(2)*mu / sigma), 'xk')\nplt.ylabel(r\"$1 - u_{NT}(0)$\")\n\nplt.subplot(212)\nfor mu in np.logspace(-1.5, 0, 20):\n    soln = solve_fredholm(k(mu, sigma), f_nt(mu, sigma), n)\n    plt.semilogx(mu, soln(np.zeros(1)), '.k')\n    plt.semilogx(mu, 1 / (1 + np.sqrt(2)*mu / sigma), 'xk')\n\nplt.xlabel(r\"$\\mu / \\sigma = \\sqrt{\\tau}/2$\")\nplt.ylabel(r\"$u_{NT}(0)$\")\nplt.ylim([0,1])\n\n(0.0, 1.0)\n\n\n\n\n\n\n\nThreat, \\(|\\mu / \\sigma| \\le 1\\)\n\nxmax = 32\nx = np.arange(0, xmax, 0.01)\n\nfor mu in [-1/16, -1/8, -1/4, -1/2, -1]:\n    soln = solve_fredholm(k(mu, sigma), f_t(), n)\n    plt.plot(x / sigma, soln(x) * (-mu / sigma), label=r\"$\\tau = $\" + f\"{-2*mu}\")\nplt.plot(x, x + 0.5, 'k')\nplt.xlim([0, 4])\nplt.ylim([0, 5])\nplt.xlabel(r\"$x / \\sqrt{\\tau}$\")\nplt.ylabel(r\"$\\frac{\\sqrt{\\tau}}{2} u(x)$\")\nplt.legend()\n\n&lt;matplotlib.legend.Legend at 0x130102910&gt;\n\n\n\n\n\n\nxmax = 32\nx = np.arange(0, xmax, 0.01)\n\nfig = plt.figure(figsize=(5.5,2.5))\n\nax = plt.subplot(122)\nfor mu in [-1/8, -1/4, -1/2, -1]:\n    soln = solve_fredholm(k(mu, sigma), f_t(), n)\n    plt.plot(x / sigma, soln(x) * (-mu / sigma), label=f\"{-2*mu}\")\nplt.plot(x, x + 0.5, 'k')\nplt.xlim([0, 4])\nplt.ylim([0, 5])\nplt.xlabel(r\"$x / \\sqrt{\\tau}$\")\nplt.ylabel(r\"$\\frac{\\sqrt{\\tau}}{2} u_{T}(x)$\")\nplt.legend(frameon=False, title=r\"$\\tau$\")\n\n\nxmax = 32\nx = np.arange(0, xmax, 0.01)\n\nax = plt.subplot(121)\nfor mu in [1/8, 1/4, 1/2, 1]:\n    soln = solve_fredholm(k(mu, sigma), f_nt(mu, sigma), n)\n    plt.semilogy(2 * mu * x / sigma**2, soln(x), label=mu)\nplt.semilogy(x, np.exp(- x), 'k')\nplt.xlim([0, 8])\nplt.ylim([1e-4,1])\nplt.xlabel(r\"$x$\")\nplt.ylabel(r\"$u_{NT}(x)$\")\n\nfig.tight_layout()\nplt.savefig(\"small_updates.png\", bbox_inches=\"tight\")\n# plt.legend()"
  },
  {
    "objectID": "decision-theory/numerical_fredholm_integral.html#scratch",
    "href": "decision-theory/numerical_fredholm_integral.html#scratch",
    "title": "Introduction",
    "section": "Scratch",
    "text": "Scratch\nAttempts at higher-order approximations, fitting the constants, etc.\n\ndef theory_nt(x, mu, sigma):\n    return (norm.cdf(-mu/sigma) / norm.cdf(mu/sigma)) * np.exp(-2 * mu * x / sigma**2)\n\ndef theory_t(x, mu, sigma):\n    a = 1 + np.abs(sigma/mu) * norm.pdf(np.abs(mu/sigma)) / norm.cdf(np.abs(mu/sigma))\n    return - (1/mu) * x + a\n\n\nmu = -2\nsigma = 1\nn = 185\n\nsoln = solve_fredholm(k(mu, sigma), f_t(), n)\n\nxmax = 6\nx = np.arange(0, xmax, 0.1)\n\nplt.plot(x, soln(x))\nplt.plot(x, theory_t(x, mu, sigma))\n# a = 1 + np.abs(sigma/mu) * norm.pdf(np.abs(mu/sigma)) / norm.cdf(np.abs(mu/sigma))\na = 1/2\nplt.plot(x, 1 - (sigma/mu)*norm.pdf((x+mu)/sigma) + (- (x/mu) + a - 1)*norm.cdf((x+mu)/sigma))\nplt.plot(x[x&lt;=-mu], 1 + norm.cdf((x[x&lt;=-mu]+mu)/sigma), ':', lw=4)\nplt.ylim([0,1 - xmax/mu])\n\n(0.0, 4.0)\n\n\n\n\n\n\ndef a_opt(x):\n    return 1/2 + 1/(2*x) - (1/x)*norm.pdf(1/2 + x/2) / norm.cdf(-(1/2 + x/2))\n\n\nmu = -1/2\nsigma = 1\nn = 185\n\nsoln = solve_fredholm(k(mu, sigma), f_t(), n)\n\nxmax = 8\nx = np.arange(0, xmax, 0.1)\n\na = 1/4\nplt.plot(x, soln(x))\nplt.plot(x, -(x/mu) + a)\nplt.plot(x, 1 - (sigma/mu)*norm.pdf((x+mu)/sigma) + (- (x/mu) + a - 1)*norm.cdf((x+mu)/sigma))\nplt.plot(x[x&lt;=-mu], 1 + norm.cdf((x[x&lt;=-mu]+mu)/sigma), ':', lw=4)\nplt.ylim([0,1 - xmax/mu])\nplt.show()\n\na = a_opt(mu/sigma)\nprint(a)\nprint(-sigma / mu * (norm.pdf(1/2) / norm.cdf(-1/2) - 1/2))\nplt.plot(x, soln(x))\nplt.plot(x, -(x/mu) + a)\nplt.plot(x, 1 - (sigma/mu)*norm.pdf((x+mu)/sigma) + (- (x/mu) + a - 1)*norm.cdf((x+mu)/sigma))\nplt.plot(x[x&lt;=-mu], 1 + norm.cdf((x[x&lt;=-mu]+mu)/sigma), ':', lw=4)\nplt.ylim([0,1 - xmax/mu])\nplt.show()\n\na = 1\nplt.plot(x, soln(x))\nplt.plot(x, -(x/mu) + a)\nplt.plot(x, 1 - (sigma/mu)*norm.pdf((x+mu)/sigma) + (- (x/mu) + a - 1)*norm.cdf((x+mu)/sigma))\nplt.plot(x[x&lt;=-mu], 1 + norm.cdf((x[x&lt;=-mu]+mu)/sigma), ':', lw=4)\nplt.ylim([0,1 - xmax/mu])\nplt.show()\n\n\n\n\n\n1.4271079588328082\n1.2821555407361296\n\n\n\n\n\n\n\n\n\nmu = -8\nsigma = 1\nn = 185\n\nsoln = solve_fredholm(k(mu, sigma), f_t(), n)\n\nxmax = 32\nx = np.arange(0, xmax, 0.1)\n\na = 1/16\nplt.plot(x, soln(x))\nplt.plot(x, -(x/mu) + a)\nplt.plot(x, 1 - (sigma/mu)*norm.pdf((x+mu)/sigma) + (- (x/mu) + a - 1)*norm.cdf((x+mu)/sigma))\nplt.plot(x[x&lt;=-mu], 1 + norm.cdf((x[x&lt;=-mu]+mu)/sigma), ':', lw=4)\nplt.vlines((-mu) / 2, 0, 1 - xmax/mu, 'k', linestyle='dashed')\nplt.ylim([0,1 - xmax/mu])\nplt.show()\n\na = 1/2\nplt.plot(x, soln(x))\nplt.plot(x, -(x/mu) + a)\nplt.plot(x, 1 - (sigma/mu)*norm.pdf((x+mu)/sigma) + (- (x/mu) + a - 1)*norm.cdf((x+mu)/sigma))\nplt.plot(x[x&lt;=-mu], 1 + norm.cdf((x[x&lt;=-mu]+mu)/sigma), ':', lw=4)\nplt.vlines((-mu) / 2, 0, 1 - xmax/mu, 'k', linestyle='dashed')\nplt.ylim([0,1 - xmax/mu])\nplt.show()\n\na = 2\nplt.plot(x, soln(x))\nplt.plot(x, -(x/mu) + a)\nplt.plot(x, 1 - (sigma/mu)*norm.pdf((x+mu)/sigma) + (- (x/mu) + a - 1)*norm.cdf((x+mu)/sigma))\nplt.plot(x[x&lt;=-mu], 1 + norm.cdf((x[x&lt;=-mu]+mu)/sigma), ':', lw=4)\nplt.vlines((-mu) / 2, 0, 1 - xmax/mu, 'k', linestyle='dashed')\nplt.ylim([0,1 - xmax/mu])\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\nmu = -4\nsigma = 1\nn = 185\n\nsoln = solve_fredholm(k(mu, sigma), f_t(), n)\n\nxmax = 12\nx = np.arange(0, xmax, 0.1)\n\na = 1/16\nplt.plot(x, soln(x))\nplt.plot(x, -(x/mu) + a)\nplt.plot(x, 1 - (sigma/mu)*norm.pdf((x+mu)/sigma) + (- (x/mu) + a - 1)*norm.cdf((x+mu)/sigma))\nplt.plot(x[x&lt;=-mu], 1 + norm.cdf((x[x&lt;=-mu]+mu)/sigma), ':', lw=4)\nplt.vlines((-mu) / 2, 0, 1 - xmax/mu, 'k', linestyle='dashed')\nplt.ylim([0,1 - xmax/mu])\nplt.show()\n\na = 1/2\nplt.plot(x, soln(x))\nplt.plot(x, -(x/mu) + a)\nplt.plot(x, 1 - (sigma/mu)*norm.pdf((x+mu)/sigma) + (- (x/mu) + a - 1)*norm.cdf((x+mu)/sigma))\nplt.plot(x[x&lt;=-mu], 1 + norm.cdf((x[x&lt;=-mu]+mu)/sigma), ':', lw=4)\nplt.vlines((-mu) / 2, 0, 1 - xmax/mu, 'k', linestyle='dashed')\nplt.ylim([0,1 - xmax/mu])\nplt.show()\n\na = 2\nplt.plot(x, soln(x))\nplt.plot(x, -(x/mu) + a)\nplt.plot(x, 1 - (sigma/mu)*norm.pdf((x+mu)/sigma) + (- (x/mu) + a - 1)*norm.cdf((x+mu)/sigma))\nplt.plot(x[x&lt;=-mu], 1 + norm.cdf((x[x&lt;=-mu]+mu)/sigma), ':', lw=4)\nplt.vlines((-mu) / 2, 0, 1 - xmax/mu, 'k', linestyle='dashed')\nplt.ylim([0,1 - xmax/mu])\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\nmu = -1/4\nsigma = 1\nn = 185\n\nsoln = solve_fredholm(k(mu, sigma), f_t(), n)\n\nxmax = 4\nx = np.arange(0, xmax, 0.01)\n\na = 1/2\nplt.plot(x, soln(x))\nplt.plot(x, -(x/mu) + a)\nplt.plot(x, 1 - (sigma/mu)*norm.pdf((x+mu)/sigma) + (- (x/mu) + a - 1)*norm.cdf((x+mu)/sigma))\nplt.ylim([0,1 - xmax/mu])\nplt.show()\n\na = 0.641 * sigma / (-mu)\nplt.plot(x, soln(x))\nplt.plot(x, -(x/mu) + a)\nplt.plot(x, 1 - (sigma/mu)*norm.pdf((x+mu)/sigma) + (- (x/mu) + a - 1)*norm.cdf((x+mu)/sigma))\nplt.ylim([0,1 - xmax/mu])\nplt.show()\n\na = 5\nplt.plot(x, soln(x))\nplt.plot(x, -(x/mu) + a)\nplt.plot(x, 1 - (sigma/mu)*norm.pdf((x+mu)/sigma) + (- (x/mu) + a - 1)*norm.cdf((x+mu)/sigma))\nplt.ylim([0,1 - xmax/mu])\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nmu = -1\nsigma = 1\nn = 185\n\nsoln = solve_fredholm(k(mu, sigma), f_t(), n)\n\nxmax = 4\nx = np.arange(0, xmax, 0.01)\n\na = 1/2\nplt.plot(x, soln(x))\nplt.plot(x, -(x/mu) + a)\nplt.plot(x, 1 - (sigma/mu)*norm.pdf((x+mu)/sigma) + (- (x/mu) + a - 1)*norm.cdf((x+mu)/sigma))\nplt.ylim([0,1 - xmax/mu])\nplt.show()\n\na = 0.9\nplt.plot(x, soln(x))\nplt.plot(x, -(x/mu) + a)\nplt.plot(x, 1 - (sigma/mu)*norm.pdf((x+mu)/sigma) + (- (x/mu) + a - 1)*norm.cdf((x+mu)/sigma))\nplt.ylim([0,1 - xmax/mu])\nplt.show()\n\na = 2\nplt.plot(x, soln(x))\nplt.plot(x, -(x/mu) + a)\nplt.plot(x, 1 - (sigma/mu)*norm.pdf((x+mu)/sigma) + (- (x/mu) + a - 1)*norm.cdf((x+mu)/sigma))\nplt.ylim([0,1 - xmax/mu])\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nmu = -4\nsigma = 1\nn = 185\n\nsoln = solve_fredholm(k(mu, sigma), f_t(), n)\n\nxmax = 12\nx = np.arange(0, xmax, 0.1)\n\nplt.plot(x, soln(x))\na = 1/2\nplt.plot(x, -(x/mu) + a)\nplt.plot(x, 1 - (sigma/mu)*norm.pdf((x+mu)/sigma) + (- (x/mu) + a - 1)*norm.cdf((x+mu)/sigma))\nplt.ylim([0,1 - xmax/mu])\n\n(0.0, 4.0)\n\n\n\n\n\n\nxmax = 32\nx = np.arange(0, xmax, 0.01)\n\nfor mu in [1/8, 1/4, 1/2, 1]:\n    a = norm.cdf(-mu / sigma)\n    soln = solve_fredholm(k(mu, sigma), f_nt(mu, sigma), n)\n    plt.semilogy(x, soln(x), label=mu)\n    plt.semilogy(x, a * np.exp(-2 * mu * x / sigma**2))\n    plt.semilogy(x, a * norm.sf(-(x+mu)/sigma) * np.exp(-2 * mu * x / sigma**2) + norm.cdf(-(x+mu)/sigma))\n    # plt.semilogy(x, np.exp(-2 * x), 'k')\n    # plt.xlim([0,4])\n    # plt.ylim([3e-3,1.1])\n    plt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmu = -1/8\nsigma = 1\nn = 185\n\nsoln = solve_fredholm(k(mu, sigma), f_t(), n)\n\nxmax = 4\nx = np.arange(0, xmax, 0.1)\n\nplt.plot(x, soln(x))\na = 2 * np.sqrt(2*np.pi)\nplt.plot(x, -(x/mu) + a)\nplt.plot(x, 1 - (sigma/mu)*norm.pdf((x+mu)/sigma) + (- (x/mu) + a - 1)*norm.cdf((x+mu)/sigma))\nplt.ylim([0,1 - xmax/mu])\n\n(0.0, 33.0)\n\n\n\n\n\n\nnp.sqrt(2*np.pi)\n\n2.5066282746310002\n\n\n\nmu = -1/4\nsigma = 1\nn = 185\n\nsoln = solve_fredholm(k(mu, sigma), f_t(), n)\n\nxmax = 4\nx = np.arange(0, xmax, 0.1)\n\nplt.plot(x, soln(x))\na = np.sqrt(2*np.pi)\nplt.plot(x, -(x/mu) + a)\nplt.plot(x, 1 - (sigma/mu)*norm.pdf((x+mu)/sigma) + (- (x/mu) + a - 1)*norm.cdf((x+mu)/sigma))\nplt.ylim([0,1 - xmax/mu])\n\n(0.0, 17.0)\n\n\n\n\n\n\nmu = -1/2\nsigma = 1\nn = 185\n\nsoln = solve_fredholm(k(mu, sigma), f_t(), n)\n\nxmax = 4\nx = np.arange(0, xmax, 0.1)\n\nplt.plot(x, soln(x))\na = np.sqrt(2*np.pi) / 2\nplt.plot(x, -(x/mu) + a)\nplt.plot(x, 1 - (sigma/mu)*norm.pdf((x+mu)/sigma) + (- (x/mu) + a - 1)*norm.cdf((x+mu)/sigma))\nplt.ylim([0,1 - xmax/mu])\n\n(0.0, 9.0)\n\n\n\n\n\n\nplt.loglog([1/2, 1/4, 1/8], [1, 2, 4], '.')\n\n\n\n\n\nmu = -1/4\nsigma = 1\nn = 185\n\nsoln = solve_fredholm(k(mu, sigma), f_t(), n)\n\nxmax = 16\nx = np.arange(0, xmax, 0.1)\n\nplt.plot(x, soln(x))\nplt.plot(x, theory_t(x, mu, sigma))\nplt.plot(x[x&lt;=-mu], 1 + norm.cdf((x[x&lt;=-mu]+mu)/sigma))\nplt.plot(x[x&gt;=-mu], -x[x&gt;=-mu]/mu + 1/2)\nplt.ylim([0,1 - xmax/mu])\n\n(0.0, 65.0)\n\n\n\n\n\n\nsigma = 1\nn = 185\nxmax = 4\nx = np.arange(0, xmax, 0.1)\n\nfor mu in [-1/2, -1/3, -1/4, -1/5]:\n    soln = solve_fredholm(k(mu, sigma), f_t(), n)\n    mod = soln(x) * -mu - x\n    plt.plot(x, mod - mod[-1])\n    # plt.plot(x, theory_t(x, mu, sigma) * -mu)\n\n\n\n\n\nmu = 2\nsigma = 1\nn = 185\n\nsoln = solve_fredholm(k(mu, sigma), f_nt(mu, sigma), n)\n\nxmax = 10\nx = np.arange(0, xmax, 0.1)\n\nplt.semilogy(x, soln(x))\n# plt.plot(x, 1 + norm.cdf((x+mu)/sigma))\n# plt.plot(x, 1 - x/mu)\nplt.semilogy(x, theory_nt(x, mu, sigma))\nplt.semilogy(x[x&lt;=mu], norm.cdf(-(x[x&lt;=mu]+mu)/sigma))\nplt.semilogy(x[x&gt;mu], np.exp(2*(mu/sigma)**2) * norm.cdf(-2*mu/sigma) * np.exp(-2*mu * x[x&gt;mu] / sigma**2))\n# plt.plot(x, -x/mu + norm.cdf(0))\n# plt.ylim([0,1 - xmax/mu])"
  },
  {
    "objectID": "notebooks/2023-09-15-qpcr_analysis.html",
    "href": "notebooks/2023-09-15-qpcr_analysis.html",
    "title": "2023-09-13 Extraction Experiment 2 qPCR Analysis",
    "section": "",
    "text": "Testing the efficacy of RNA extraction kits. See experiment google doc."
  },
  {
    "objectID": "notebooks/2023-09-15-qpcr_analysis.html#objectives",
    "href": "notebooks/2023-09-15-qpcr_analysis.html#objectives",
    "title": "2023-09-13 Extraction Experiment 2 qPCR Analysis",
    "section": "",
    "text": "Testing the efficacy of RNA extraction kits. See experiment google doc."
  },
  {
    "objectID": "notebooks/2023-09-15-qpcr_analysis.html#preliminary-work",
    "href": "notebooks/2023-09-15-qpcr_analysis.html#preliminary-work",
    "title": "2023-09-13 Extraction Experiment 2 qPCR Analysis",
    "section": "Preliminary work",
    "text": "Preliminary work\n\nOlivia put the .eds files in NAO qPCR data/Olivia on Google Drive and shared the folder with Dan.\nGoogle Drive for desktop only syncs shared drives, not shared folders in other drives, so Dan figured out a work around. He made a shortcut to the shared folder in his own google drive so it would sync locally.\nOpened up the .eds files in Design and Analysis locally and exported to .csv and saved those in the airport experiment folder on the main google drive.\nFound a Google Sheet with metadata, downloaded as CSV and added the CSV back to the Google Drive"
  },
  {
    "objectID": "notebooks/2023-09-15-qpcr_analysis.html#data-import",
    "href": "notebooks/2023-09-15-qpcr_analysis.html#data-import",
    "title": "2023-09-13 Extraction Experiment 2 qPCR Analysis",
    "section": "Data import",
    "text": "Data import\n\nlibrary(readr)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(purrr)\nlibrary(stringr)\nlibrary(ggplot2)\nlibrary(tidyr)\n\n\ndata_dir &lt;- \"~/airport/[2023-09-06] Extraction-kit comparison 2: Settled Solids/\"\nfilename_pattern &lt;- \"Results\"\n\n\ncol_types &lt;- list(\n                  Target=col_character(),\n                  Cq=col_double()\n                  )\nraw_data &lt;- list.files(\n                       paste(data_dir, \"qpcr\", sep=\"\"),\n                       pattern = filename_pattern,\n                       full.names = TRUE,\n                       ) |&gt;\n  map(function(f) read_csv(f, skip=23,\n                       col_types=col_types,\n                       )) |&gt;\n  list_rbind()\n\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\n\nprint(raw_data)\n\n# A tibble: 369 × 21\n    Well `Well Position` Omit  Sample Target Task     Reporter Quencher\n   &lt;dbl&gt; &lt;chr&gt;           &lt;lgl&gt; &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;   \n 1     1 A1              FALSE 1A     Cov2   UNKNOWN  FAM      NFQ-MGB \n 2     2 A2              FALSE 1A     Cov2   UNKNOWN  FAM      NFQ-MGB \n 3     3 A3              FALSE 1A     Cov2   UNKNOWN  FAM      NFQ-MGB \n 4     4 A4              FALSE 3C     Cov2   UNKNOWN  FAM      NFQ-MGB \n 5     5 A5              FALSE 3C     Cov2   UNKNOWN  FAM      NFQ-MGB \n 6     6 A6              FALSE 3C     Cov2   UNKNOWN  FAM      NFQ-MGB \n 7     7 A7              FALSE 6B     Cov2   UNKNOWN  FAM      NFQ-MGB \n 8     8 A8              FALSE 6B     Cov2   UNKNOWN  FAM      NFQ-MGB \n 9     9 A9              FALSE 6B     Cov2   UNKNOWN  FAM      NFQ-MGB \n10    10 A10             FALSE 1000.0 Cov2   STANDARD FAM      NFQ-MGB \n# ℹ 359 more rows\n# ℹ 13 more variables: `Amp Status` &lt;chr&gt;, `Amp Score` &lt;dbl&gt;,\n#   `Curve Quality` &lt;lgl&gt;, `Result Quality Issues` &lt;lgl&gt;, Cq &lt;dbl&gt;,\n#   `Cq Confidence` &lt;dbl&gt;, `Cq Mean` &lt;dbl&gt;, `Cq SD` &lt;dbl&gt;,\n#   `Auto Threshold` &lt;lgl&gt;, Threshold &lt;dbl&gt;, `Auto Baseline` &lt;lgl&gt;,\n#   `Baseline Start` &lt;dbl&gt;, `Baseline End` &lt;dbl&gt;\n\n\n\nraw_data\n\n# A tibble: 369 × 21\n    Well `Well Position` Omit  Sample Target Task     Reporter Quencher\n   &lt;dbl&gt; &lt;chr&gt;           &lt;lgl&gt; &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;   \n 1     1 A1              FALSE 1A     Cov2   UNKNOWN  FAM      NFQ-MGB \n 2     2 A2              FALSE 1A     Cov2   UNKNOWN  FAM      NFQ-MGB \n 3     3 A3              FALSE 1A     Cov2   UNKNOWN  FAM      NFQ-MGB \n 4     4 A4              FALSE 3C     Cov2   UNKNOWN  FAM      NFQ-MGB \n 5     5 A5              FALSE 3C     Cov2   UNKNOWN  FAM      NFQ-MGB \n 6     6 A6              FALSE 3C     Cov2   UNKNOWN  FAM      NFQ-MGB \n 7     7 A7              FALSE 6B     Cov2   UNKNOWN  FAM      NFQ-MGB \n 8     8 A8              FALSE 6B     Cov2   UNKNOWN  FAM      NFQ-MGB \n 9     9 A9              FALSE 6B     Cov2   UNKNOWN  FAM      NFQ-MGB \n10    10 A10             FALSE 1000.0 Cov2   STANDARD FAM      NFQ-MGB \n# ℹ 359 more rows\n# ℹ 13 more variables: `Amp Status` &lt;chr&gt;, `Amp Score` &lt;dbl&gt;,\n#   `Curve Quality` &lt;lgl&gt;, `Result Quality Issues` &lt;lgl&gt;, Cq &lt;dbl&gt;,\n#   `Cq Confidence` &lt;dbl&gt;, `Cq Mean` &lt;dbl&gt;, `Cq SD` &lt;dbl&gt;,\n#   `Auto Threshold` &lt;lgl&gt;, Threshold &lt;dbl&gt;, `Auto Baseline` &lt;lgl&gt;,\n#   `Baseline Start` &lt;dbl&gt;, `Baseline End` &lt;dbl&gt;\n\n\n\nmetadata &lt;- read_csv(paste(data_dir, \"[2023-09-11] Extraction Experiment 2 templates and results - sampleMetadata.csv\", sep=\"\"))\n\nRows: 21 Columns: 9\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (6): Sample_ID, Extraction_kit, Short_kit, Elution_format, Brand, NA_Target\ndbl (2): Kit Batch, Elution_volume\nlgl (1): FP_sampleID\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nglimpse(metadata)\n\nRows: 21\nColumns: 9\n$ Sample_ID      &lt;chr&gt; \"1A\", \"1B\", \"1C\", \"2A\", \"2B\", \"2C\", \"3A\", \"3B\", \"3C\", \"…\n$ Extraction_kit &lt;chr&gt; \"Zymo quick-RNA\", \"Zymo quick-RNA\", \"Zymo quick-RNA\", \"…\n$ Short_kit      &lt;chr&gt; \"1_ZR\", \"1_ZR\", \"1_ZR\", \"2_ZD\", \"2_ZD\", \"2_ZD\", \"3_IPL\"…\n$ `Kit Batch`    &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3…\n$ Elution_volume &lt;dbl&gt; 30, 30, 30, 100, 100, 100, 100, 100, 100, 60, 60, 60, 1…\n$ Elution_format &lt;chr&gt; \"15*2\", \"15*2\", \"15*2\", \"50*2\", \"50*2\", \"50*2\", \"50*2\",…\n$ Brand          &lt;chr&gt; \"Zymo\", \"Zymo\", \"Zymo\", \"Zymo\", \"Zymo\", \"Zymo\", \"Invitr…\n$ NA_Target      &lt;chr&gt; \"RNA\", \"RNA\", \"RNA\", \"DNA+RNA\", \"DNA+RNA\", \"DNA+RNA\", \"…\n$ FP_sampleID    &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n\n\n\ntidy_data &lt;- raw_data |&gt;\n  mutate(\n    Cq = as.double(Cq),\n    replicate = str_extract(Sample, \"[A-Z]\"),\n    Sample_ID = str_split_i(Sample, \"/\", 1),\n    dilution = as.integer(str_split_i(Sample, \"/\", 2)),\n    quantity = as.double(Sample),\n  ) |&gt;\n  mutate(dilution = replace_na(dilution, 1)) |&gt;\n  left_join(\n    metadata,\n    by=join_by(Sample_ID)\n  )\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `quantity = as.double(Sample)`.\nCaused by warning:\n! NAs introduced by coercion\n\nglimpse(tidy_data)\n\nRows: 369\nColumns: 33\n$ Well                    &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14,…\n$ `Well Position`         &lt;chr&gt; \"A1\", \"A2\", \"A3\", \"A4\", \"A5\", \"A6\", \"A7\", \"A8\"…\n$ Omit                    &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALS…\n$ Sample                  &lt;chr&gt; \"1A\", \"1A\", \"1A\", \"3C\", \"3C\", \"3C\", \"6B\", \"6B\"…\n$ Target                  &lt;chr&gt; \"Cov2\", \"Cov2\", \"Cov2\", \"Cov2\", \"Cov2\", \"Cov2\"…\n$ Task                    &lt;chr&gt; \"UNKNOWN\", \"UNKNOWN\", \"UNKNOWN\", \"UNKNOWN\", \"U…\n$ Reporter                &lt;chr&gt; \"FAM\", \"FAM\", \"FAM\", \"FAM\", \"FAM\", \"FAM\", \"FAM…\n$ Quencher                &lt;chr&gt; \"NFQ-MGB\", \"NFQ-MGB\", \"NFQ-MGB\", \"NFQ-MGB\", \"N…\n$ `Amp Status`            &lt;chr&gt; \"AMP\", \"AMP\", \"AMP\", \"AMP\", \"AMP\", \"AMP\", \"NO_…\n$ `Amp Score`             &lt;dbl&gt; 1.1701024, 1.0212594, 1.1604009, 1.1057531, 1.…\n$ `Curve Quality`         &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ `Result Quality Issues` &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ Cq                      &lt;dbl&gt; 32.44077, 35.24757, 33.72678, 34.44077, 34.704…\n$ `Cq Confidence`         &lt;dbl&gt; 0.9451320, 0.9773032, 0.9759027, 0.9634213, 0.…\n$ `Cq Mean`               &lt;dbl&gt; 33.80504, 33.80504, 33.80504, 34.31332, 34.313…\n$ `Cq SD`                 &lt;dbl&gt; 1.4050310, 1.4050310, 1.4050310, 0.4683633, 0.…\n$ `Auto Threshold`        &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE…\n$ Threshold               &lt;dbl&gt; 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04…\n$ `Auto Baseline`         &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE…\n$ `Baseline Start`        &lt;dbl&gt; 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3…\n$ `Baseline End`          &lt;dbl&gt; 29, 32, 30, 31, 31, 31, 31, 31, 31, 21, 21, 21…\n$ replicate               &lt;chr&gt; \"A\", \"A\", \"A\", \"C\", \"C\", \"C\", \"B\", \"B\", \"B\", N…\n$ Sample_ID               &lt;chr&gt; \"1A\", \"1A\", \"1A\", \"3C\", \"3C\", \"3C\", \"6B\", \"6B\"…\n$ dilution                &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ quantity                &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, 1000, 1000…\n$ Extraction_kit          &lt;chr&gt; \"Zymo quick-RNA\", \"Zymo quick-RNA\", \"Zymo quic…\n$ Short_kit               &lt;chr&gt; \"1_ZR\", \"1_ZR\", \"1_ZR\", \"3_IPL\", \"3_IPL\", \"3_I…\n$ `Kit Batch`             &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 3, 3, 3, NA, NA, NA, 1, 1, 1…\n$ Elution_volume          &lt;dbl&gt; 30, 30, 30, 100, 100, 100, 80, 80, 80, NA, NA,…\n$ Elution_format          &lt;chr&gt; \"15*2\", \"15*2\", \"15*2\", \"50*2\", \"50*2\", \"50*2\"…\n$ Brand                   &lt;chr&gt; \"Zymo\", \"Zymo\", \"Zymo\", \"Invitrogen\", \"Invitro…\n$ NA_Target               &lt;chr&gt; \"RNA\", \"RNA\", \"RNA\", \"RNA\", \"RNA\", \"RNA\", \"RNA…\n$ FP_sampleID             &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n\n\n\nWith equal Cq axes\n\ntidy_data |&gt;\n  filter(!is.na(Extraction_kit),\n         dilution == 1,\n         ) |&gt;\n  ggplot(mapping = aes(x=Cq,\n                       y=Extraction_kit,\n                       color=replicate,\n                       )\n  ) +\n  stat_summary(\n    fun.min = min,\n    fun.max = max,\n    fun = median,\n    position = position_dodge(width = 0.2),\n    size = 0.2\n  ) + \n  facet_wrap(facets = ~Target)\n\nWarning: Removed 4 rows containing non-finite values (`stat_summary()`).\n\n\n\n\n\n\n\nWith free Cq axes\n\ntidy_data |&gt;\n  filter(!is.na(Extraction_kit),\n         dilution == 1,\n         ) |&gt;\n  ggplot(mapping = aes(x=Cq,\n                       y=Extraction_kit,\n                       color=replicate,\n                       )\n  ) +\n  stat_summary(\n    fun.min = min,\n    fun.max = max,\n    fun = median,\n    position = position_dodge(width = 0.2),\n    size = 0.2\n  ) + \n  facet_wrap(facets = ~Target, scales=\"free_x\")\n\nWarning: Removed 4 rows containing non-finite values (`stat_summary()`).\n\n\n\n\n\nCheck that the overlapping points really do have three values\n\ntidy_data |&gt;\n  filter(!is.na(Extraction_kit), is.na(Cq)) |&gt;\n  count(Target, Extraction_kit, Sample_ID, dilution) |&gt;\n  print()\n\n# A tibble: 17 × 5\n   Target Extraction_kit                    Sample_ID dilution     n\n   &lt;chr&gt;  &lt;chr&gt;                             &lt;chr&gt;        &lt;int&gt; &lt;int&gt;\n 1 Cov2   Invitrogen PureLink RNA           3C              10     2\n 2 Cov2   Invitrogen PureLink RNA           3C             100     2\n 3 Cov2   NucleoSpin Virus                  4B               1     2\n 4 Cov2   QIAamp Viral RNA mini kit         6A               1     1\n 5 Cov2   QIAamp Viral RNA mini kit         6C              10     1\n 6 Cov2   QIAamp Viral RNA mini kit         6C             100     2\n 7 Cov2   Qiagen AllPrep PowerViral DNA/RNA 7A               1     1\n 8 Cov2   Qiagen AllPrep PowerViral DNA/RNA 7C              10     2\n 9 Cov2   Qiagen AllPrep PowerViral DNA/RNA 7C             100     2\n10 Noro   Invitrogen PureLink RNA           3C              10     1\n11 Noro   Invitrogen PureLink RNA           3C             100     1\n12 Noro   QIAamp Viral RNA mini kit         6C              10     1\n13 Noro   QIAamp Viral RNA mini kit         6C             100     1\n14 Noro   Qiagen AllPrep PowerViral DNA/RNA 7C              10     1\n15 Noro   Qiagen AllPrep PowerViral DNA/RNA 7C             100     1\n16 Noro   Zymo quick-RNA                    1C              10     1\n17 Noro   Zymo quick-RNA                    1C             100     1\n\n\n\ntidy_data |&gt;\n    filter(Extraction_kit==\"Zymo quick-RNA\",\n           Target==\"CrA\", replicate==\"A\") |&gt;\n    print(width=Inf)\n\n# A tibble: 3 × 33\n   Well `Well Position` Omit  Sample Target Task    Reporter Quencher\n  &lt;dbl&gt; &lt;chr&gt;           &lt;lgl&gt; &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt;   &lt;chr&gt;    &lt;chr&gt;   \n1     1 A1              FALSE 1A     CrA    UNKNOWN FAM      NFQ-MGB \n2     2 A2              FALSE 1A     CrA    UNKNOWN FAM      NFQ-MGB \n3     3 A3              FALSE 1A     CrA    UNKNOWN FAM      NFQ-MGB \n  `Amp Status` `Amp Score` `Curve Quality` `Result Quality Issues`    Cq\n  &lt;chr&gt;              &lt;dbl&gt; &lt;lgl&gt;           &lt;lgl&gt;                   &lt;dbl&gt;\n1 AMP                 1.41 NA              NA                       21.1\n2 AMP                 1.43 NA              NA                       21.0\n3 AMP                 1.42 NA              NA                       21.1\n  `Cq Confidence` `Cq Mean` `Cq SD` `Auto Threshold` Threshold `Auto Baseline`\n            &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;lgl&gt;                &lt;dbl&gt; &lt;lgl&gt;          \n1           0.989      21.1  0.0535 TRUE                 0.175 TRUE           \n2           0.989      21.1  0.0535 TRUE                 0.175 TRUE           \n3           0.989      21.1  0.0535 TRUE                 0.175 TRUE           \n  `Baseline Start` `Baseline End` replicate Sample_ID dilution quantity\n             &lt;dbl&gt;          &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;        &lt;int&gt;    &lt;dbl&gt;\n1                3             16 A         1A               1       NA\n2                3             15 A         1A               1       NA\n3                3             16 A         1A               1       NA\n  Extraction_kit Short_kit `Kit Batch` Elution_volume Elution_format Brand\n  &lt;chr&gt;          &lt;chr&gt;           &lt;dbl&gt;          &lt;dbl&gt; &lt;chr&gt;          &lt;chr&gt;\n1 Zymo quick-RNA 1_ZR                1             30 15*2           Zymo \n2 Zymo quick-RNA 1_ZR                1             30 15*2           Zymo \n3 Zymo quick-RNA 1_ZR                1             30 15*2           Zymo \n  NA_Target FP_sampleID\n  &lt;chr&gt;     &lt;lgl&gt;      \n1 RNA       NA         \n2 RNA       NA         \n3 RNA       NA"
  },
  {
    "objectID": "notebooks/2023-09-15-qpcr_analysis.html#standard-curves",
    "href": "notebooks/2023-09-15-qpcr_analysis.html#standard-curves",
    "title": "2023-09-13 Extraction Experiment 2 qPCR Analysis",
    "section": "Standard curves",
    "text": "Standard curves\n\ntidy_data |&gt;\n  filter(Task == \"STANDARD\",\n         dilution == 1,\n         ) |&gt;\n  ggplot(mapping = aes(x=quantity,\n                       y=Cq,\n                       )\n  ) +\n  stat_summary(\n    fun.min = min,\n    fun.max = max,\n    fun = median,\n    position = position_dodge(width = 0.2),\n    size = 0.2\n  ) + \n  geom_smooth(method='lm') + \n  scale_x_continuous(trans='log10') + \n  facet_wrap(facets = ~Target, scales=\"free_x\")\n\nWarning: Removed 4 rows containing non-finite values (`stat_summary()`).\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 4 rows containing non-finite values (`stat_smooth()`).\n\n\n\n\n\nNot sure what the units of the X-axis are\n\nlibrary(broom)\nfits &lt;- tibble()\nfor (target in unique(tidy_data$Target)){\n    fit &lt;- lm(Cq ~ log10(quantity),\n       data=filter(tidy_data, Task==\"STANDARD\", Target==target)\n    ) |&gt;\n    tidy() |&gt;\n    mutate(Target=target, efficiency=10^-(1/estimate) - 1)\n    fits &lt;- bind_rows(fits, fit)\n}\nprint(fits |&gt; filter(term == \"log10(quantity)\"))\n\n# A tibble: 4 × 7\n  term            estimate std.error statistic  p.value Target efficiency\n  &lt;chr&gt;              &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;\n1 log10(quantity)    -2.61    0.143      -18.2 1.23e-10 Cov2         1.42\n2 log10(quantity)    -2.85    0.108      -26.4 5.34e-12 Noro         1.24\n3 log10(quantity)    -2.59    0.0703     -36.8 1.58e-14 CrA          1.43\n4 log10(quantity)    -2.68    0.148      -18.1 1.32e-10 16S          1.36\n\n\nThese match the Design & Analysis software."
  },
  {
    "objectID": "notebooks/2023-09-15-qpcr_analysis.html#dilution-series",
    "href": "notebooks/2023-09-15-qpcr_analysis.html#dilution-series",
    "title": "2023-09-13 Extraction Experiment 2 qPCR Analysis",
    "section": "Dilution series",
    "text": "Dilution series\n\ntidy_data |&gt;\n  filter(Task == \"UNKNOWN\", dilution &gt; 1) |&gt;\n  count(Target, Extraction_kit, dilution)\n\n# A tibble: 21 × 4\n   Target Extraction_kit                    dilution     n\n   &lt;chr&gt;  &lt;chr&gt;                                &lt;int&gt; &lt;int&gt;\n 1 Cov2   Invitrogen PureLink RNA                 10     2\n 2 Cov2   Invitrogen PureLink RNA                100     2\n 3 Cov2   QIAamp Viral RNA mini kit               10     2\n 4 Cov2   QIAamp Viral RNA mini kit              100     2\n 5 Cov2   Qiagen AllPrep PowerViral DNA/RNA       10     2\n 6 Cov2   Qiagen AllPrep PowerViral DNA/RNA      100     2\n 7 CrA    Invitrogen PureLink RNA                 10     2\n 8 CrA    Invitrogen PureLink RNA                100     2\n 9 CrA    QIAamp Viral RNA mini kit               10     2\n10 CrA    QIAamp Viral RNA mini kit              100     2\n# ℹ 11 more rows\n\n\n\ntidy_data |&gt;\n  filter(Task == \"UNKNOWN\",\n         ) |&gt;\n  ggplot(mapping = aes(x=dilution,\n                       y=Cq,\n                       )\n  ) +\n  geom_point() + \n  geom_smooth(method='lm') + \n  scale_x_continuous(trans='log10') + \n  facet_grid(rows=vars(Extraction_kit), cols=vars(Target))\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 23 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 23 rows containing missing values (`geom_point()`)."
  },
  {
    "objectID": "notebooks/2023-09-15-qpcr_analysis.html#amplification-curves",
    "href": "notebooks/2023-09-15-qpcr_analysis.html#amplification-curves",
    "title": "2023-09-13 Extraction Experiment 2 qPCR Analysis",
    "section": "Amplification curves",
    "text": "Amplification curves"
  },
  {
    "objectID": "notebooks/2023-09-15-qpcr_analysis.html#todo",
    "href": "notebooks/2023-09-15-qpcr_analysis.html#todo",
    "title": "2023-09-13 Extraction Experiment 2 qPCR Analysis",
    "section": "TODO",
    "text": "TODO\n\nBoxplots\nThere are a few NaNs that show up as missing points and aren’t evident in the plot. Will investigate later.\n~Standard curve data~\nDiluted samples\nAmplification curves"
  },
  {
    "objectID": "notebooks/2023-09-08_SequencingCosts.html",
    "href": "notebooks/2023-09-08_SequencingCosts.html",
    "title": "Airport experiment sequencing cost estimate",
    "section": "",
    "text": "We are planning to sequence samples from four sources (redacted because this is publicly visible). We will receive one sample from each source each day weekday for eight weeks. Thus we will have \\(8 \\times 5 \\times 4 = 160\\) samples total.\nWe will the following steps ourselves:\nThen we will deliver the RNA extracts to the BioMicroCenter for:\nThe goal of this doc is to estimate the cost of library prep and sequencing."
  },
  {
    "objectID": "notebooks/2023-09-08_SequencingCosts.html#sources",
    "href": "notebooks/2023-09-08_SequencingCosts.html#sources",
    "title": "Airport experiment sequencing cost estimate",
    "section": "Sources",
    "text": "Sources\n\nThe cost of library prep and sequencing come from the BioMicroCenter’s pricing page. We use the MIT prices.\nCharacteristics of the NovaSeq come from illumina (Table 1)."
  },
  {
    "objectID": "notebooks/2023-09-08_SequencingCosts.html#estimate",
    "href": "notebooks/2023-09-08_SequencingCosts.html#estimate",
    "title": "Airport experiment sequencing cost estimate",
    "section": "Estimate",
    "text": "Estimate\nEach NovaSeq flow cell has 4 lanes. When run in 2 x 150 bp mode, it generates 150 basepair forward and reverse read pairs for 300 bp per read pair. In one run, the flow cell generates 2400–3000 Gb of data. In the following we will make a conservative estimate by using the lower end of the range.\n\nlanes_per_flow_cell = 4\nbp_per_read_pair = 300\ngb_per_flow_cell = 2400\n\nread_pairs_per_flow_cell = gb_per_flow_cell * 1e9 / bp_per_read_pair\nread_pairs_per_lane = read_pairs_per_flow_cell / lanes_per_flow_cell\nprint(f\"We expect at least {read_pairs_per_lane/1e6} M read pairs per lane\")\n\nWe expect at least 2000.0 M read pairs per lane\n\n\nThe smallest unit of NovaSeq sequencing we can buy is one lane, which costs $5,940. We also pay $258.5 per sample for library preparation.\n\ncost_per_lane = 5940\nlibrary_cost_per_sample = 258.5\n\nWe’ll consider three options:\n\nSequencing all 160 samples in 4 lanes\nSequencing all 160 samples in 8 lanes\nSequencing MWF only (\\(160 \\times 3/5 = 96\\) samples) in 5 lanes\n\n\nfor num_samples, num_lanes in [(160, 4), (160, 8), (96, 5)]:\n    samples_per_lane = num_samples / num_lanes\n    read_pairs_per_sample = read_pairs_per_lane / samples_per_lane\n    sequencing_cost = cost_per_lane * num_lanes\n    library_cost = library_cost_per_sample * num_samples\n    total_cost = sequencing_cost + library_cost\n    cost_per_sample = total_cost / num_samples\n    cost_per_read_pair = cost_per_sample / read_pairs_per_sample\n    print(f\"\"\"\n    {num_samples} samples in {num_lanes} lanes:\n        Million read pairs per sample:\\t{read_pairs_per_sample / 1e6:3,.0f}\n        Sequencing cost:\\t${sequencing_cost:7,.0f} \n        Library prep cost:\\t${library_cost:7,.0f}\n        Total cost:\\t\\t\\t${total_cost:7,.0f}\n        Cost per sample:\\t${cost_per_sample:7,.0f}\n        Cost per M rp:\\t\\t${cost_per_read_pair * 1e6:10.2f}\n    \"\"\")\n\n\n    160 samples in 4 lanes:\n        Million read pairs per sample:   50\n        Sequencing cost:    $ 23,760 \n        Library prep cost:  $ 41,360\n        Total cost:         $ 65,120\n        Cost per sample:    $    407\n        Cost per M rp:      $      8.14\n    \n\n    160 samples in 8 lanes:\n        Million read pairs per sample:  100\n        Sequencing cost:    $ 47,520 \n        Library prep cost:  $ 41,360\n        Total cost:         $ 88,880\n        Cost per sample:    $    556\n        Cost per M rp:      $      5.56\n    \n\n    96 samples in 5 lanes:\n        Million read pairs per sample:  104\n        Sequencing cost:    $ 29,700 \n        Library prep cost:  $ 24,816\n        Total cost:         $ 54,516\n        Cost per sample:    $    568\n        Cost per M rp:      $      5.45"
  }
]